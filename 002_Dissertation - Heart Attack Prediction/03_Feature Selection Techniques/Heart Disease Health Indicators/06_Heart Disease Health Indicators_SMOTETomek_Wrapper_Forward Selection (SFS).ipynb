{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f807d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df= pd.read_csv('C://Users//User//Desktop//MSc Westminster//Dissertation//DataSets//Heart_Disease_Indicators.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d77e531a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.90582\n",
      "1    0.09418\n",
      "Name: HeartDiseaseorAttack, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_size = 50000\n",
    "\n",
    "num_class_0 = int(target_size * df['HeartDiseaseorAttack'].value_counts(normalize=True)[0])\n",
    "num_class_1 = target_size - num_class_0\n",
    "\n",
    "df_class_0 = df[df['HeartDiseaseorAttack'] == 0]\n",
    "df_class_1 = df[df['HeartDiseaseorAttack'] == 1]\n",
    "\n",
    "df_class_0_sampled = df_class_0.sample(n=num_class_0, random_state=15)\n",
    "df_class_1_sampled = df_class_1.sample(n=num_class_1, random_state=15)\n",
    "\n",
    "df_sampled = pd.concat([df_class_0_sampled, df_class_1_sampled])\n",
    "\n",
    "df_sampled = df_sampled.sample(frac=1, random_state=15).reset_index(drop=True)\n",
    "df= df_sampled\n",
    "print(df['HeartDiseaseorAttack'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfa3c756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48050, 22)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace= True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "453b65ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    40175\n",
      "1     6968\n",
      "Name: Diabetes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df= df[df['Diabetes'] != 1].copy()\n",
    "df.loc[df['Diabetes'] == 2, 'Diabetes'] = 1\n",
    "print(df['Diabetes'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c05e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns= ['HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'Diabetes', 'PhysActivity',\n",
    "                      'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk',\n",
    "                      'Sex', 'Age', 'Education', 'Income'\n",
    "                     ]\n",
    "df[categorical_columns]= df[categorical_columns].astype(str)\n",
    "df= pd.get_dummies(df, columns= categorical_columns, drop_first= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "151027e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop(['HeartDiseaseorAttack'], axis= 1)\n",
    "y= df['HeartDiseaseorAttack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e49eb021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2, random_state= 15, stratify= y)\n",
    "\n",
    "continuous_columns = ['BMI', 'GenHlth', 'MentHlth', 'PhysHlth']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss= StandardScaler()\n",
    "X_train= ss.fit_transform(X_train)\n",
    "X_test= ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16e9e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt= SMOTETomek(random_state= 15)\n",
    "X_sm_tl, y_sm_tl= smt.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00333eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({0: 34065, 1: 3649})\n",
      "Resampled class distribution: Counter({0: 33993, 1: 33993})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "original_distribution = Counter(y_train)\n",
    "print(f\"Original class distribution: {original_distribution}\")\n",
    "\n",
    "\n",
    "resampled_distribution = Counter(y_sm_tl)\n",
    "print(f\"Resampled class distribution: {resampled_distribution}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf5ba8",
   "metadata": {},
   "source": [
    "--- LogisticRegression ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f982495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "790b3cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      8517\n",
      "           1       0.28      0.25      0.26       912\n",
      "\n",
      "    accuracy                           0.86      9429\n",
      "   macro avg       0.60      0.59      0.59      9429\n",
      "weighted avg       0.86      0.86      0.86      9429\n",
      "\n",
      "Precision: 0.27697841726618705\n",
      "Accuracy: 0.8638243716194718\n",
      "AUC: 0.641667130136013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, roc_auc_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr= LogisticRegression(random_state= 15)\n",
    "\n",
    "sfs= SequentialFeatureSelector(lr, n_features_to_select= 10, direction= 'forward', scoring= 'precision')\n",
    "sfs.fit(X_sm_tl, y_sm_tl)\n",
    "selected_features= sfs.get_support()\n",
    "\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "\n",
    "lr.fit(X_sm_tl_selected, y_sm_tl)\n",
    "y_pred_lr= lr.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_lr= lr.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_lr, labels= lr.classes_)\n",
    "print(classification_report(y_test, y_pred_lr, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_lr, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_lr))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f446a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "935a91fa",
   "metadata": {},
   "source": [
    "--- DecisionTreeClassifier ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17227aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f328e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      8517\n",
      "           1       0.00      0.00      0.00       912\n",
      "\n",
      "    accuracy                           0.90      9429\n",
      "   macro avg       0.45      0.50      0.47      9429\n",
      "weighted avg       0.82      0.90      0.86      9429\n",
      "\n",
      "Precision: 0.0\n",
      "Accuracy: 0.9031710679817584\n",
      "AUC: 0.6484498109045069\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt= DecisionTreeClassifier(random_state=15)\n",
    "\n",
    "sfs= SequentialFeatureSelector(dt, n_features_to_select= 10, direction= 'forward', scoring= 'precision')\n",
    "sfs.fit(X_sm_tl, y_sm_tl)\n",
    "selected_features= sfs.get_support()\n",
    "\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "\n",
    "dt.fit(X_sm_tl_selected, y_sm_tl)\n",
    "y_pred_dt= dt.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_dt= dt.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_dt, labels= dt.classes_)\n",
    "print(classification_report(y_test, y_pred_dt, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_dt, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_dt))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5ed7fc",
   "metadata": {},
   "source": [
    "--- Tuned - DecisionTreeClassifier ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0fbe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb57a7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "Best Precision Score: 0.9408415474451101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid= {\n",
    "             'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "             'min_samples_split': [2, 10, 20],\n",
    "             'min_samples_leaf': [1, 5, 10],\n",
    "             'max_features': [None, 'sqrt', 'log2'],\n",
    "             'criterion': ['gini', 'entropy']\n",
    "            }\n",
    "\n",
    "gs_dt= GridSearchCV(estimator= dt, param_grid= param_grid, cv= 5, scoring= 'precision')\n",
    "gs_dt.fit(X_sm_tl, y_sm_tl)\n",
    "\n",
    "print(\"Best Parameters:\", gs_dt.best_params_)\n",
    "print(\"Best Precision Score:\", gs_dt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e0146a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      8517\n",
      "           1       0.00      0.00      0.00       912\n",
      "\n",
      "    accuracy                           0.90      9429\n",
      "   macro avg       0.45      0.50      0.47      9429\n",
      "weighted avg       0.82      0.90      0.86      9429\n",
      "\n",
      "Precision: 0.0\n",
      "Accuracy: 0.9032771237671015\n",
      "AUC: 0.6434745962152062\n"
     ]
    }
   ],
   "source": [
    "tuned_dt= gs_dt.best_estimator_\n",
    "\n",
    "sfs= SequentialFeatureSelector(tuned_dt, n_features_to_select= 10, direction= 'forward', scoring= 'precision')\n",
    "sfs.fit(X_sm_tl, y_sm_tl)\n",
    "selected_features = sfs.get_support()\n",
    "\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "tuned_dt.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "y_pred_tuned_dt= tuned_dt.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_dt= tuned_dt.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_dt, labels= tuned_dt.classes_)\n",
    "print(classification_report(y_test, y_pred_tuned_dt, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_dt, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_dt))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04681239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da98fb3b",
   "metadata": {},
   "source": [
    "--- KNeighborsClassifier ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432e3c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5aacb03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94      8517\n",
      "           1       0.30      0.15      0.20       912\n",
      "\n",
      "    accuracy                           0.88      9429\n",
      "   macro avg       0.61      0.56      0.57      9429\n",
      "weighted avg       0.85      0.88      0.87      9429\n",
      "\n",
      "Precision: 0.3006396588486141\n",
      "Accuracy: 0.8834446919079436\n",
      "AUC: 0.6735623180882816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn= KNeighborsClassifier()\n",
    "\n",
    "sfs= SequentialFeatureSelector(knn, n_features_to_select= 10, direction= 'forward', scoring= 'precision')\n",
    "sfs.fit(X_sm_tl, y_sm_tl)\n",
    "selected_features= sfs.get_support()\n",
    "\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "\n",
    "knn.fit(X_sm_tl_selected, y_sm_tl)\n",
    "y_pred_knn= knn.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_knn= knn.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_knn, labels= knn.classes_)\n",
    "print(classification_report(y_test, y_pred_knn, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_knn, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_knn))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a13f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fcc60fe",
   "metadata": {},
   "source": [
    "--- Tuned - KNeighborsClassifier ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f25b087f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "Best Precision Score: 0.9311578759522989\n"
     ]
    }
   ],
   "source": [
    "param_grid= {\n",
    "             'n_neighbors': np.arange(1,40),\n",
    "             'weights': ['uniform', 'distance'],\n",
    "             'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "            }\n",
    "\n",
    "gs_knn= GridSearchCV(estimator= knn, param_grid= param_grid, cv=5, scoring= 'precision')\n",
    "gs_knn.fit(X_sm_tl, y_sm_tl)\n",
    "print(\"Best Parameters:\", gs_knn.best_params_)\n",
    "print(\"Best Precision Score:\", gs_knn.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26be4e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      8517\n",
      "           1       0.29      0.00      0.01       912\n",
      "\n",
      "    accuracy                           0.90      9429\n",
      "   macro avg       0.59      0.50      0.48      9429\n",
      "weighted avg       0.84      0.90      0.86      9429\n",
      "\n",
      "Precision: 0.2857142857142857\n",
      "Accuracy: 0.902640789055043\n",
      "AUC: 0.5881861148703624\n"
     ]
    }
   ],
   "source": [
    "tuned_knn= gs_knn.best_estimator_\n",
    "\n",
    "sfs= SequentialFeatureSelector(tuned_knn, n_features_to_select= 10, direction= 'forward', scoring= 'precision')\n",
    "sfs.fit(X_sm_tl, y_sm_tl)\n",
    "selected_features = sfs.get_support()\n",
    "\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "tuned_knn.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "y_pred_tuned_knn= tuned_knn.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_knn= tuned_knn.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_knn, labels= tuned_knn.classes_)\n",
    "print(classification_report(y_test, y_pred_tuned_knn, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_knn, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_knn))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80894d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa848951",
   "metadata": {},
   "source": [
    "--- GaussianNB ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dbd7832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      8517\n",
      "           1       0.29      0.24      0.26       912\n",
      "\n",
      "    accuracy                           0.87      9429\n",
      "   macro avg       0.60      0.59      0.59      9429\n",
      "weighted avg       0.86      0.87      0.86      9429\n",
      "\n",
      "Precision: 0.28797886393659183\n",
      "Accuracy: 0.8692332166719695\n",
      "AUC: 0.7370724237798912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb= GaussianNB()\n",
    "\n",
    "sfs= SequentialFeatureSelector(nb, n_features_to_select= 10, direction= 'forward', scoring= 'precision')\n",
    "sfs.fit(X_sm_tl, y_sm_tl)\n",
    "selected_features= sfs.get_support()\n",
    "\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "\n",
    "nb.fit(X_sm_tl_selected, y_sm_tl)\n",
    "y_pred_nb= nb.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_nb= nb.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_nb, labels= nb.classes_)\n",
    "print(classification_report(y_test, y_pred_nb, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_nb, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_nb))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56176147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64e4268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04c79ba0",
   "metadata": {},
   "source": [
    "--- Random Forest ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69542e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23d9f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf= RandomForestClassifier(random_state=15)\n",
    "\n",
    "sfs= SequentialFeatureSelector(rf, n_features_to_select= 10, direction= 'forward', scoring= 'precision')\n",
    "sfs.fit(X_sm_tl, y_sm_tl)\n",
    "selected_features= sfs.get_support()\n",
    "\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "\n",
    "rf.fit(X_sm_tl_selected, y_sm_tl)\n",
    "y_pred_rf= rf.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_rf= rf.predict_proba(X_sm_tl_test_selected)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a3a4ca9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      8517\n",
      "           1       0.00      0.00      0.00       912\n",
      "\n",
      "    accuracy                           0.90      9429\n",
      "   macro avg       0.45      0.50      0.47      9429\n",
      "weighted avg       0.82      0.90      0.86      9429\n",
      "\n",
      "Precision: 0.0\n",
      "Accuracy: 0.9032771237671015\n",
      "AUC: 0.6542583692264592\n"
     ]
    }
   ],
   "source": [
    "cm= confusion_matrix(y_test, y_pred_rf, labels= rf.classes_)\n",
    "print(classification_report(y_test, y_pred_rf, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_rf, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_rf))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f30d7119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best Precision Score: 0.9747355169512488\n"
     ]
    }
   ],
   "source": [
    "param_grid= {\n",
    "             'n_estimators': [100, 200, 300],\n",
    "             'max_depth': [None, 10, 20, 30],\n",
    "             'min_samples_split': [2, 5, 10],\n",
    "             'min_samples_leaf': [1, 2, 4],\n",
    "            }\n",
    "\n",
    "gs_tuned_rf= GridSearchCV(estimator= rf, param_grid= param_grid, cv= 5, scoring= 'precision', n_jobs= -1, verbose= 2)\n",
    "gs_tuned_rf.fit(X_sm_tl, y_sm_tl)\n",
    "print(\"Best Parameters:\", gs_tuned_rf.best_params_)\n",
    "print(\"Best Precision Score:\", gs_tuned_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "741c1f08",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m tuned_rf\u001b[38;5;241m=\u001b[39m gs_tuned_rf\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m      3\u001b[0m sfs\u001b[38;5;241m=\u001b[39m SequentialFeatureSelector(tuned_rf, n_features_to_select\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, direction\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m'\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43msfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_sm_tl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_sm_tl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m sfs\u001b[38;5;241m.\u001b[39mget_support()\n\u001b[0;32m      7\u001b[0m X_sm_tl_selected\u001b[38;5;241m=\u001b[39m X_sm_tl[:, selected_features]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_sequential.py:276\u001b[0m, in \u001b[0;36mSequentialFeatureSelector.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    274\u001b[0m is_auto_select \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_to_select \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[1;32m--> 276\u001b[0m     new_feature_idx, new_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_best_new_feature_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcloned_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_mask\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_auto_select \u001b[38;5;129;01mand\u001b[39;00m ((new_score \u001b[38;5;241m-\u001b[39m old_score) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol):\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_sequential.py:307\u001b[0m, in \u001b[0;36mSequentialFeatureSelector._get_best_new_feature_score\u001b[1;34m(self, estimator, X, y, current_mask)\u001b[0m\n\u001b[0;32m    305\u001b[0m         candidate_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mcandidate_mask\n\u001b[0;32m    306\u001b[0m     X_new \u001b[38;5;241m=\u001b[39m X[:, candidate_mask]\n\u001b[1;32m--> 307\u001b[0m     scores[feature_idx] \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m    315\u001b[0m new_feature_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(scores, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m feature_idx: scores[feature_idx])\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_feature_idx, scores[new_feature_idx]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:224\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_classification:\n\u001b[1;32m--> 224\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(y)\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py:210\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_classification_targets\u001b[39m(y):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;124;03m\"\"\"Ensure that target y is of a non-regression type.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    Only the following target types (as defined in type_of_target) are allowed:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m        Target values.\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    217\u001b[0m     ]:\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py:386\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m# Check multiclass\u001b[39;00m\n\u001b[0;32m    385\u001b[0m first_row \u001b[38;5;241m=\u001b[39m y[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(y) \u001b[38;5;28;01melse\u001b[39;00m y\u001b[38;5;241m.\u001b[39mgetrow(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m--> 386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(first_row) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;66;03m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py:84\u001b[0m, in \u001b[0;36m_NumPyApiWrapper.unique_values\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:272\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    270\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:333\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    331\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 333\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[0;32m    335\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuned_rf= gs_tuned_rf.best_estimator_\n",
    "\n",
    "sfs= SequentialFeatureSelector(tuned_rf, n_features_to_select= 10, direction= 'forward', scoring= 'precision')\n",
    "sfs.fit(X_sm_tl, y_sm_tl)\n",
    "selected_features = sfs.get_support()\n",
    "\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "tuned_rf.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "y_pred_tuned_rf= tuned_rf.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_rf= tuned_rf.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_rf, labels= tuned_rf.classes_)\n",
    "print(classification_report(y_test, y_pred_tuned_rf, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_rf, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_rf))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a70a30",
   "metadata": {},
   "source": [
    "--- AdaBoost ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e0218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada= AdaBoostClassifier(random_state=15)\n",
    "\n",
    "sfs= SequentialFeatureSelector(ada, n_features_to_select= 10, direction= 'forward', scoring= 'precision')\n",
    "sfs.fit(X_sm_tl, y_sm_tl)\n",
    "selected_features= sfs.get_support()\n",
    "\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "\n",
    "ada.fit(X_sm_tl_selected, y_sm_tl)\n",
    "y_pred_ada= ada.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_ada= ada.predict_proba(X_sm_tl_test_selected)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a43f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm= confusion_matrix(y_test, y_pred_ada, labels= ada.classes_)\n",
    "print(classification_report(y_test, y_pred_ada, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_ada, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_ada))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708588e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid= {'n_estimators': [50, 100, 200]}\n",
    "\n",
    "gs_ada= GridSearchCV(estimator= ada, param_grid= param_grid, cv= 5, scoring= 'precision', n_jobs= -1, verbose= 2)\n",
    "gs_ada.fit(X_sm_tl, y_sm_tl)\n",
    "print(\"Best Parameters:\", gs_ada.best_params_)\n",
    "print(\"Best Precision Score:\", gs_ada.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85b3030",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_ada= gs_ada.best_estimator_\n",
    "\n",
    "sfs= SequentialFeatureSelector(tuned_ada, n_features_to_select= 10, direction= 'forward', scoring= 'precision')\n",
    "sfs.fit(X_sm_tl, y_sm_tl)\n",
    "selected_features = sfs.get_support()\n",
    "\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "tuned_ada.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "y_pred_tuned_ada= tuned_ada.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_ada= tuned_ada.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_ada, labels= tuned_ada.classes_)\n",
    "print(classification_report(y_test, y_pred_tuned_ada, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_ada, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_ada))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a91d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a74a4591",
   "metadata": {},
   "source": [
    "--- GradientBoosting ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc7e71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "grb= GradientBoostingClassifier(random_state=15)\n",
    "\n",
    "sfs= SequentialFeatureSelector(grb, n_features_to_select= 10, direction= 'forward', scoring= 'precision')\n",
    "sfs.fit(X_sm_tl, y_sm_tl)\n",
    "selected_features= sfs.get_support()\n",
    "\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "\n",
    "grb.fit(X_sm_tl_selected, y_sm_tl)\n",
    "y_pred_grb= grb.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_grb= grb.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_grb, labels= grb.classes_)\n",
    "print(classification_report(y_test, y_pred_grb, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_grb, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_grb))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_grb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1020da31",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid= {'learning_rate': [0.01, 0.1, 0.2]}\n",
    "\n",
    "gs_grb= GridSearchCV(estimator= grb, param_grid= param_grid, cv= 5, scoring= 'precision', n_jobs= -1, verbose= 2)\n",
    "gs_grb.fit(X_sm_tl, y_sm_tl)\n",
    "\n",
    "print(\"Best Parameters:\", gs_grb.best_params_)\n",
    "print(\"Best Precision Score:\", gs_grb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb445f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_grb= gs_grb.best_estimator_\n",
    "\n",
    "sfs= SequentialFeatureSelector(tuned_grb, n_features_to_select= 10, direction= 'forward', scoring= 'precision')\n",
    "sfs.fit(X_sm_tl, y_sm_tl)\n",
    "selected_features = sfs.get_support()\n",
    "\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "tuned_grb.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "y_pred_tuned_grb= tuned_grb.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_grb= tuned_grb.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_grb, labels= tuned_grb.classes_)\n",
    "print(classification_report(y_test, y_pred_tuned_grb, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_grb, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_grb))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_grb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9496232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29ff8e08",
   "metadata": {},
   "source": [
    "--- XGB ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8943f6b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb= XGBClassifier(random_state=15)\n",
    "\n",
    "sfs= SequentialFeatureSelector(xgb, n_features_to_select= 10, direction= 'forward', scoring= 'precision')\n",
    "sfs.fit(X_sm_tl, y_sm_tl)\n",
    "selected_features= sfs.get_support()\n",
    "\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "\n",
    "xgb.fit(X_sm_tl_selected, y_sm_tl)\n",
    "y_pred_xgb= xgb.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_xgb= xgb.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_xgb, labels= xgb.classes_)\n",
    "print(classification_report(y_test, y_pred_xgb, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_xgb, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_xgb))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da093569",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_XGBoost= {'learning_rate': [0.01, 0.1, 1.0]}\n",
    "\n",
    "gs_xgb= GridSearchCV(estimator= xgb, param_grid= params_XGBoost, cv= 5, scoring= 'precision', n_jobs= -1, verbose= 2)\n",
    "gs_xgb.fit(X_sm_tl, y_sm_tl)\n",
    "\n",
    "print(\"Best Parameters:\", gs_xgb.best_params_)\n",
    "print(\"Best Precision Score:\", gs_xgb.best_score_)\n",
    "\n",
    "tuned_xgb= gs_xgb.best_estimator_\n",
    "\n",
    "sfs= SequentialFeatureSelector(tuned_xgb, n_features_to_select= 10, direction= 'forward', scoring= 'precision')\n",
    "sfs.fit(X_sm_tl, y_sm_tl)\n",
    "selected_features = sfs.get_support()\n",
    "\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "tuned_xgb.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "y_pred_tuned_xgb= tuned_xgb.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_xgb= tuned_xgb.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_xgb, labels= tuned_xgb.classes_)\n",
    "print(classification_report(y_test, y_pred_tuned_xgb, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_xgb, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_xgb))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bd651d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe4ddc2b",
   "metadata": {},
   "source": [
    "--- LGBM ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1effa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgm= LGBMClassifier(random_state=15)\n",
    "\n",
    "sfs= SequentialFeatureSelector(lgm, n_features_to_select= 10, direction= 'forward', scoring= 'precision')\n",
    "sfs.fit(X_sm_tl, y_sm_tl)\n",
    "selected_features= sfs.get_support()\n",
    "\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "\n",
    "\n",
    "lgm.fit(X_sm_tl_selected, y_sm_tl)\n",
    "y_pred_lgm= lgm.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_lgm= lgm.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_lgm, labels= lgm.classes_)\n",
    "print(classification_report(y_test, y_pred_lgm, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_lgm, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_lgm))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_lgm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dec891",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_LGB= {'learning_rate': [0.001, 0.01, 0.1, 1.0],\n",
    "             'num_leaves': [31, 127],\n",
    "             'reg_alpha': [0.1, 0.5],\n",
    "             'min_data_in_leaf': [30, 50, 100, 300, 400]}\n",
    "\n",
    "gs_lgm= GridSearchCV(estimator= lgm, param_grid= params_LGB, cv=5, scoring='precision', n_jobs=-1, verbose=2)\n",
    "gs_lgm.fit(X_sm_tl, y_sm_tl)\n",
    "\n",
    "print(\"Best Parameters:\", gs_lgm.best_params_)\n",
    "print(\"Best Precision Score:\", gs_lgm.best_score_)\n",
    "\n",
    "tuned_lgm= gs_lgm.best_estimator_\n",
    "\n",
    "sfs= SequentialFeatureSelector(tuned_lgm, n_features_to_select= 10, direction= 'forward', scoring= 'precision')\n",
    "sfs.fit(X_sm_tl, y_sm_tl)\n",
    "selected_features = sfs.get_support()\n",
    "\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "tuned_lgm.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "y_pred_tuned_lgm= tuned_lgm.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_lgm= tuned_lgm.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_lgm, labels= tuned_lgm.classes_)\n",
    "print(classification_report(y_test, y_pred_tuned_lgm, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_lgm, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_lgm))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_lgm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ae9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a7670df",
   "metadata": {},
   "source": [
    "--- CatBoost ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa1cef8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat= CatBoostClassifier(random_state=15)\n",
    "\n",
    "sfs= SequentialFeatureSelector(cat, n_features_to_select= 10, direction= 'forward', scoring= 'precision')\n",
    "sfs.fit(X_sm_tl, y_sm_tl)\n",
    "selected_features= sfs.get_support()\n",
    "\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "\n",
    "cat.fit(X_sm_tl_selected, y_sm_tl)\n",
    "y_pred_cat= cat.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_cat= cat.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_cat, labels= cat.classes_)\n",
    "print(classification_report(y_test, y_pred_cat, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_cat, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_cat))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8d322e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af2c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_CatBoost= {\n",
    "                  'depth': [3,5,10],\n",
    "                  'learning_rate' : [0.01,0.1,1],\n",
    "                  'iterations' : [5,10,50,100]\n",
    "                 }\n",
    "\n",
    "gs_cat= GridSearchCV(estimator= cat, param_grid= params_CatBoost, cv=5, scoring='precision', n_jobs=-1, verbose=2)\n",
    "gs_cat.fit(X_sm_tl, y_sm_tl)\n",
    "\n",
    "print(\"Best Parameters:\", gs_cat.best_params_)\n",
    "print(\"Best Precision Score:\", gs_cat.best_score_)\n",
    "\n",
    "tuned_cat= gs_cat.best_estimator_\n",
    "\n",
    "sfs= SequentialFeatureSelector(tuned_cat, n_features_to_select= 10, direction= 'forward', scoring= 'precision')\n",
    "sfs.fit(X_sm_tl, y_sm_tl)\n",
    "selected_features = sfs.get_support()\n",
    "\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "tuned_cat.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "\n",
    "y_pred_tuned_cat= tuned_cat.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_cat= tuned_cat.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_cat, labels= tuned_cat.classes_)\n",
    "print(classification_report(y_test, y_pred_tuned_cat, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_cat, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_cat))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44677a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d3077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b57855ee",
   "metadata": {},
   "source": [
    "--- Visualisation ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9984fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_scores= {\n",
    "                    'Logistic Regression Precision:': precision_score(y_test, y_pred_lr, zero_division= 0),\n",
    "                    'Decision Tree Precision:': precision_score(y_test, y_pred_dt, zero_division= 0),\n",
    "                    'Tuned Decision Tree Precision:': precision_score(y_test, y_pred_tuned_dt, zero_division= 0),\n",
    "                    'KNeighborsClassifier Precision:': precision_score(y_test, y_pred_knn, zero_division= 0),\n",
    "                    'Tuned KNeighborsClassifier Precision:': precision_score(y_test, y_pred_tuned_knn, zero_division= 0),\n",
    "                    'GaussianNB Precision:': precision_score(y_test, y_pred_nb, zero_division= 0),\n",
    "                    'Random Forest Precision:': precision_score(y_test, y_pred_rf, zero_division= 0),\n",
    "                    'Tuned Random Forest Precision:': precision_score(y_test, y_pred_tuned_rf, zero_division= 0),\n",
    "                    'AdaBoost Precision:': precision_score(y_test, y_pred_ada, zero_division= 0),\n",
    "                    'Tuned AdaBoost Precision:': precision_score(y_test, y_pred_tuned_ada, zero_division= 0),\n",
    "                    'GradientBoosting Precision:': precision_score(y_test, y_pred_grb, zero_division= 0),\n",
    "                    'Tuned GradientBoosting Precision:': precision_score(y_test, y_pred_tuned_grb, zero_division= 0),\n",
    "                    'XGB Precision:': precision_score(y_test, y_pred_xgb, zero_division= 0),\n",
    "                    'Tuned XGB Precision:': precision_score(y_test, y_pred_tuned_xgb, zero_division= 0),\n",
    "                    'LGBM Precision:': precision_score(y_test, y_pred_lgm, zero_division= 0),\n",
    "                    'Tuned LGBM Precision:': precision_score(y_test, y_pred_tuned_lgm, zero_division= 0),\n",
    "                    'CatBoost Precision:': precision_score(y_test, y_pred_cat, zero_division= 0),\n",
    "                    'Tuned CatBoost Precision:': precision_score(y_test, y_pred_tuned_cat, zero_division= 0)\n",
    "                  }\n",
    "\n",
    "sfs_precision= pd.DataFrame(list(precision_scores.items()), columns= ['Model', 'Precision Score'])\n",
    "sfs_precision= sfs_precision.sort_values(by= 'Precision Score', ascending=False)\n",
    "print(sfs_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b0ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores= {\n",
    "                    'Logistic Regression Accuracy:': accuracy_score(y_test, y_pred_lr),\n",
    "                    'Decision Tree Accuracy:': accuracy_score(y_test, y_pred_dt),\n",
    "                    'Tuned Decision Tree Accuracy:': accuracy_score(y_test, y_pred_tuned_dt),\n",
    "                    'KNeighborsClassifier Accuracy:': accuracy_score(y_test, y_pred_knn),\n",
    "                    'Tuned KNeighborsClassifier Accuracy:': accuracy_score(y_test, y_pred_tuned_knn),\n",
    "                    'GaussianNB Accuracy:': accuracy_score(y_test, y_pred_nb),\n",
    "                    'Random Forest Accuracy:': accuracy_score(y_test, y_pred_rf),\n",
    "                    'Tuned Random Forest Accuracy:': accuracy_score(y_test, y_pred_tuned_rf),\n",
    "                    'AdaBoost Accuracy:': accuracy_score(y_test, y_pred_ada),\n",
    "                    'Tuned AdaBoost Accuracy:': accuracy_score(y_test, y_pred_tuned_ada),\n",
    "                    'GradientBoosting Accuracy:': accuracy_score(y_test, y_pred_grb),\n",
    "                    'Tuned GradientBoosting Accuracy:': accuracy_score(y_test, y_pred_tuned_grb),\n",
    "                    'XGB Accuracy:': accuracy_score(y_test, y_pred_xgb),\n",
    "                    'Tuned XGB Accuracy:': accuracy_score(y_test, y_pred_tuned_xgb),\n",
    "                    'LGBM Accuracy:': accuracy_score(y_test, y_pred_lgm),\n",
    "                    'Tuned LGBM Accuracy:': accuracy_score(y_test, y_pred_tuned_lgm),\n",
    "                    'CatBoost Accuracy:': accuracy_score(y_test, y_pred_cat),\n",
    "                    'Tuned CatBoost Accuracy:': accuracy_score(y_test, y_pred_tuned_cat)\n",
    "                  }\n",
    "\n",
    "sfs_accuracy= pd.DataFrame(list(accuracy_scores.items()), columns= ['Model', 'Accuracy Score'])\n",
    "sfs_accuracy= sfs_accuracy.sort_values(by= 'Accuracy Score', ascending=False)\n",
    "print(sfs_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f99f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_scores= {\n",
    "                    'Logistic Regression AUC:': roc_auc_score(y_test, y_pred_prob_lr),\n",
    "                    'Decision Tree AUC:': roc_auc_score(y_test, y_pred_prob_dt),\n",
    "                    'Tuned Decision Tree AUC:': roc_auc_score(y_test, y_pred_prob_tuned_dt),\n",
    "                    'KNeighborsClassifier AUC:': roc_auc_score(y_test, y_pred_prob_knn),\n",
    "                    'Tuned KNeighborsClassifier AUC:': roc_auc_score(y_test, y_pred_prob_tuned_knn),\n",
    "                    'GaussianNB AUC:': roc_auc_score(y_test, y_pred_prob_nb),\n",
    "                    'SVM AUC:': roc_auc_score(y_test, y_pred_prob_svc),\n",
    "                    'Tuned Random Forest AUC:': roc_auc_score(y_test, y_pred_prob_tuned_rf),\n",
    "                    'AdaBoost AUC:': roc_auc_score(y_test, y_pred_prob_ada),\n",
    "                    'Tuned AdaBoost AUC:': roc_auc_score(y_test, y_pred_prob_tuned_ada),\n",
    "                    'GradientBoosting AUC:': roc_auc_score(y_test, y_pred_prob_grb),\n",
    "                    'Tuned GradientBoosting AUC:': roc_auc_score(y_test, y_pred_prob_tuned_grb),\n",
    "                    'XGB AUC:': roc_auc_score(y_test, y_pred_prob_xgb),\n",
    "                    'Tuned XGB AUC:': roc_auc_score(y_test, y_pred_prob_tuned_xgb),\n",
    "                    'LGBM AUC:': roc_auc_score(y_test, y_pred_prob_lgm),\n",
    "                    'Tuned LGBM AUC:': roc_auc_score(y_test, y_pred_prob_tuned_lgm),\n",
    "                    'CatBoost AUC:': roc_auc_score(y_test, y_pred_prob_cat),\n",
    "                    'Tuned CatBoost AUC:': roc_auc_score(y_test, y_pred_prob_tuned_cat)\n",
    "                  }\n",
    "\n",
    "sfs_auc= pd.DataFrame(list(auc_scores.items()), columns= ['Model', 'AUC Score'])\n",
    "sfs_auc= sfs_auc.sort_values(by= 'AUC Score', ascending=False)\n",
    "print(sfs_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2ac15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dee7d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d9919c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011f3570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
