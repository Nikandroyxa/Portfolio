{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f807d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df= pd.read_csv('C://Users//User//Desktop//MSc Westminster//Dissertation//DataSets//Heart_Attack_Prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d77e531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=df.columns\n",
    "\n",
    "for column in columns:\n",
    "    if df[column].dtype==\"int32\":\n",
    "        df[column]=df[column].astype(\"int16\")\n",
    "    elif df[column].dtype==\"float64\":\n",
    "        df[column]=df[column].astype(\"float16\")\n",
    "    elif df[column].dtype==\"object\":\n",
    "        df[column]=df[column].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfa3c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex']= df['Sex'].map({'Female': 0, 'Male': 1})\n",
    "df['Sex']= pd.to_numeric(df['Sex'])\n",
    "\n",
    "df['Diet']= df['Diet'].map({'Healthy': 0, 'Average': 1, 'Unhealthy':2})\n",
    "df['Diet']= pd.to_numeric(df['Diet'])\n",
    "\n",
    "df[['HBP', 'LBP']]= df['Blood Pressure'].str.split('/', expand= True)\n",
    "df['HBP']= pd.to_numeric(df['HBP'])\n",
    "df['LBP']= pd.to_numeric(df['LBP'])\n",
    "\n",
    "df['Diabetes'] = df['Diabetes'].map({0: 1, 1: 0})\n",
    "\n",
    "df['Exercise Hours Per Week']= round(df['Exercise Hours Per Week'], 0)\n",
    "\n",
    "df['Sedentary Hours Per Day']= round(df['Sedentary Hours Per Day'], 0)\n",
    "\n",
    "df['Income']= round(df['Income'], 0)\n",
    "\n",
    "df['BMI']= round(df['BMI'], 0)\n",
    "\n",
    "df = df.drop(columns=['Patient ID', 'Blood Pressure', 'Country', 'Continent', 'Hemisphere'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b65ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "151027e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop(['Heart Attack Risk'], axis= 1)\n",
    "y= df['Heart Attack Risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e49eb021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2, random_state= 15, stratify= y)\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler= RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train= scaler.transform(X_train)\n",
    "X_test= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e9e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "sm= ClusterCentroids(random_state= 15, estimator= KMeans(n_init= 10))\n",
    "tl= SMOTE(random_state= 15)\n",
    "\n",
    "X_sm, y_sm= sm.fit_resample(X_train, y_train)\n",
    "X_sm_tl, y_sm_tl= tl.fit_resample(X_sm, y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3174413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.01)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso= Lasso(alpha= 0.01)\n",
    "lasso.fit(X_sm_tl, y_sm_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c963a403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features selected: 2\n"
     ]
    }
   ],
   "source": [
    "selected_features= np.where(lasso.coef_ != 0)[0]\n",
    "X_sm_tl_selected= X_sm_tl[:, selected_features]\n",
    "X_sm_tl_test_selected= X_test[:, selected_features]\n",
    "\n",
    "print(f\"Number of features selected: {len(selected_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f2d2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred= model.predict(X_test)\n",
    "    y_pred_prob= model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    print('Precision:', precision_score(y_test, y_pred, zero_division=0))\n",
    "    print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "    if y_pred_prob is not None:\n",
    "        print('AUC:', roc_auc_score(y_test, y_pred_prob))\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36010606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0bf5ba8",
   "metadata": {},
   "source": [
    "--- LogisticRegression ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f982495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "790b3cfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[650 475]\n",
      " [338 290]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.62      1125\n",
      "           1       0.38      0.46      0.42       628\n",
      "\n",
      "    accuracy                           0.54      1753\n",
      "   macro avg       0.52      0.52      0.52      1753\n",
      "weighted avg       0.56      0.54      0.54      1753\n",
      "\n",
      "Precision: 0.3790849673202614\n",
      "Accuracy: 0.5362236166571591\n",
      "AUC: 0.5153949044585987\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, roc_auc_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr= LogisticRegression(random_state= 15)\n",
    "\n",
    "train_and_evaluate_model(lr, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df820e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "935a91fa",
   "metadata": {},
   "source": [
    "--- DecisionTreeClassifier ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17227aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f328e19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 121 1004]\n",
      " [  64  564]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.11      0.18      1125\n",
      "           1       0.36      0.90      0.51       628\n",
      "\n",
      "    accuracy                           0.39      1753\n",
      "   macro avg       0.51      0.50      0.35      1753\n",
      "weighted avg       0.55      0.39      0.30      1753\n",
      "\n",
      "Precision: 0.3596938775510204\n",
      "Accuracy: 0.3907586993725043\n",
      "AUC: 0.5153949044585987\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt= DecisionTreeClassifier(random_state=15)\n",
    "\n",
    "train_and_evaluate_model(dt, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13bd342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b5ed7fc",
   "metadata": {},
   "source": [
    "--- Tuned - DecisionTreeClassifier ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0fbe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb57a7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 20, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Precision Score: 0.5997437966358685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid= {\n",
    "             'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "             'min_samples_split': [2, 10, 20],\n",
    "             'min_samples_leaf': [1, 5, 10],\n",
    "             'max_features': [None, 'sqrt', 'log2'],\n",
    "             'criterion': ['gini', 'entropy']\n",
    "            }\n",
    "\n",
    "gs_dt= GridSearchCV(estimator= dt, param_grid= param_grid, cv= 5, scoring= 'precision')\n",
    "gs_dt.fit(X_sm_tl, y_sm_tl)\n",
    "\n",
    "print(\"Best Parameters:\", gs_dt.best_params_)\n",
    "print(\"Best Precision Score:\", gs_dt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e0146a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 121 1004]\n",
      " [  64  564]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.11      0.18      1125\n",
      "           1       0.36      0.90      0.51       628\n",
      "\n",
      "    accuracy                           0.39      1753\n",
      "   macro avg       0.51      0.50      0.35      1753\n",
      "weighted avg       0.55      0.39      0.30      1753\n",
      "\n",
      "Precision: 0.3596938775510204\n",
      "Accuracy: 0.3907586993725043\n",
      "AUC: 0.5153949044585987\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tuned_dt= gs_dt.best_estimator_\n",
    "train_and_evaluate_model(tuned_dt, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04681239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da98fb3b",
   "metadata": {},
   "source": [
    "--- KNeighborsClassifier ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432e3c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5aacb03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1125    0]\n",
      " [ 628    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78      1125\n",
      "           1       0.00      0.00      0.00       628\n",
      "\n",
      "    accuracy                           0.64      1753\n",
      "   macro avg       0.32      0.50      0.39      1753\n",
      "weighted avg       0.41      0.64      0.50      1753\n",
      "\n",
      "Precision: 0.0\n",
      "Accuracy: 0.6417569880205363\n",
      "AUC: 0.5\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn= KNeighborsClassifier()\n",
    "train_and_evaluate_model(knn, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a13f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fcc60fe",
   "metadata": {},
   "source": [
    "--- Tuned - KNeighborsClassifier ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f25b087f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 38, 'weights': 'uniform'}\n",
      "Best Precision Score: 0.531881225382125\n"
     ]
    }
   ],
   "source": [
    "param_grid= {\n",
    "             'n_neighbors': np.arange(1,40),\n",
    "             'weights': ['uniform', 'distance'],\n",
    "             'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "            }\n",
    "\n",
    "gs_knn= GridSearchCV(estimator= knn, param_grid= param_grid, cv=5, scoring= 'precision')\n",
    "gs_knn.fit(X_sm_tl, y_sm_tl)\n",
    "print(\"Best Parameters:\", gs_knn.best_params_)\n",
    "print(\"Best Precision Score:\", gs_knn.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26be4e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1125    0]\n",
      " [ 628    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78      1125\n",
      "           1       0.00      0.00      0.00       628\n",
      "\n",
      "    accuracy                           0.64      1753\n",
      "   macro avg       0.32      0.50      0.39      1753\n",
      "weighted avg       0.41      0.64      0.50      1753\n",
      "\n",
      "Precision: 0.0\n",
      "Accuracy: 0.6417569880205363\n",
      "AUC: 0.5\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tuned_knn= gs_knn.best_estimator_\n",
    "train_and_evaluate_model(tuned_knn, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80894d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa848951",
   "metadata": {},
   "source": [
    "--- GaussianNB ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dbd7832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[650 475]\n",
      " [338 290]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.62      1125\n",
      "           1       0.38      0.46      0.42       628\n",
      "\n",
      "    accuracy                           0.54      1753\n",
      "   macro avg       0.52      0.52      0.52      1753\n",
      "weighted avg       0.56      0.54      0.54      1753\n",
      "\n",
      "Precision: 0.3790849673202614\n",
      "Accuracy: 0.5362236166571591\n",
      "AUC: 0.5153949044585987\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb= GaussianNB()\n",
    "train_and_evaluate_model(nb, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56176147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cc62ec3",
   "metadata": {},
   "source": [
    "--- SVM ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446f144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f655fef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 121 1004]\n",
      " [  64  564]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.11      0.18      1125\n",
      "           1       0.36      0.90      0.51       628\n",
      "\n",
      "    accuracy                           0.39      1753\n",
      "   macro avg       0.51      0.50      0.35      1753\n",
      "weighted avg       0.55      0.39      0.30      1753\n",
      "\n",
      "Precision: 0.3596938775510204\n",
      "Accuracy: 0.3907586993725043\n",
      "AUC: 0.5231726822363766\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc= SVC(kernel= 'rbf',probability= True, gamma= 1, random_state=15)\n",
    "train_and_evaluate_model(svc, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64e4268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04c79ba0",
   "metadata": {},
   "source": [
    "--- Random Forest ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69542e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23d9f00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 121 1004]\n",
      " [  64  564]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.11      0.18      1125\n",
      "           1       0.36      0.90      0.51       628\n",
      "\n",
      "    accuracy                           0.39      1753\n",
      "   macro avg       0.51      0.50      0.35      1753\n",
      "weighted avg       0.55      0.39      0.30      1753\n",
      "\n",
      "Precision: 0.3596938775510204\n",
      "Accuracy: 0.3907586993725043\n",
      "AUC: 0.5153949044585987\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf= RandomForestClassifier(random_state=15)\n",
    "train_and_evaluate_model(rf, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f30d7119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Best Precision Score: 0.6477451699227709\n"
     ]
    }
   ],
   "source": [
    "param_grid= {\n",
    "             'n_estimators': [100, 200, 300],\n",
    "             'max_depth': [None, 10, 20, 30],\n",
    "             'min_samples_split': [2, 5, 10],\n",
    "             'min_samples_leaf': [1, 2, 4],\n",
    "            }\n",
    "\n",
    "gs_tuned_rf= GridSearchCV(estimator= rf, param_grid= param_grid, cv= 5, scoring= 'precision', n_jobs= -1, verbose= 2)\n",
    "gs_tuned_rf.fit(X_sm_tl, y_sm_tl)\n",
    "print(\"Best Parameters:\", gs_tuned_rf.best_params_)\n",
    "print(\"Best Precision Score:\", gs_tuned_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "741c1f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 121 1004]\n",
      " [  64  564]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.11      0.18      1125\n",
      "           1       0.36      0.90      0.51       628\n",
      "\n",
      "    accuracy                           0.39      1753\n",
      "   macro avg       0.51      0.50      0.35      1753\n",
      "weighted avg       0.55      0.39      0.30      1753\n",
      "\n",
      "Precision: 0.3596938775510204\n",
      "Accuracy: 0.3907586993725043\n",
      "AUC: 0.5153949044585987\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tuned_rf= gs_tuned_rf.best_estimator_\n",
    "train_and_evaluate_model(tuned_rf, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a70a30",
   "metadata": {},
   "source": [
    "--- AdaBoost ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39e0218b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[350 775]\n",
      " [193 435]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.31      0.42      1125\n",
      "           1       0.36      0.69      0.47       628\n",
      "\n",
      "    accuracy                           0.45      1753\n",
      "   macro avg       0.50      0.50      0.45      1753\n",
      "weighted avg       0.54      0.45      0.44      1753\n",
      "\n",
      "Precision: 0.359504132231405\n",
      "Accuracy: 0.4478037649743297\n",
      "AUC: 0.5153949044585987\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada= AdaBoostClassifier(random_state=15)\n",
    "train_and_evaluate_model(ada, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "708588e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best Parameters: {'n_estimators': 200}\n",
      "Best Precision Score: 0.6490728181226774\n"
     ]
    }
   ],
   "source": [
    "param_grid= {'n_estimators': [50, 100, 200]}\n",
    "\n",
    "gs_ada= GridSearchCV(estimator= ada, param_grid= param_grid, cv= 5, scoring= 'precision', n_jobs= -1, verbose= 2)\n",
    "gs_ada.fit(X_sm_tl, y_sm_tl)\n",
    "print(\"Best Parameters:\", gs_ada.best_params_)\n",
    "print(\"Best Precision Score:\", gs_ada.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d85b3030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[350 775]\n",
      " [193 435]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.31      0.42      1125\n",
      "           1       0.36      0.69      0.47       628\n",
      "\n",
      "    accuracy                           0.45      1753\n",
      "   macro avg       0.50      0.50      0.45      1753\n",
      "weighted avg       0.54      0.45      0.44      1753\n",
      "\n",
      "Precision: 0.359504132231405\n",
      "Accuracy: 0.4478037649743297\n",
      "AUC: 0.5153949044585987\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tuned_ada= gs_ada.best_estimator_\n",
    "train_and_evaluate_model(tuned_ada, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a91d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a74a4591",
   "metadata": {},
   "source": [
    "--- GradientBoosting ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39fc7e71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 121 1004]\n",
      " [  64  564]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.11      0.18      1125\n",
      "           1       0.36      0.90      0.51       628\n",
      "\n",
      "    accuracy                           0.39      1753\n",
      "   macro avg       0.51      0.50      0.35      1753\n",
      "weighted avg       0.55      0.39      0.30      1753\n",
      "\n",
      "Precision: 0.3596938775510204\n",
      "Accuracy: 0.3907586993725043\n",
      "AUC: 0.5153949044585987\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "grb= GradientBoostingClassifier(random_state=15)\n",
    "train_and_evaluate_model(grb, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1020da31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best Parameters: {'learning_rate': 0.2}\n",
      "Best Precision Score: 0.6642793434216976\n"
     ]
    }
   ],
   "source": [
    "param_grid= {'learning_rate': [0.01, 0.1, 0.2]}\n",
    "\n",
    "gs_grb= GridSearchCV(estimator= grb, param_grid= param_grid, cv= 5, scoring= 'precision', n_jobs= -1, verbose= 2)\n",
    "gs_grb.fit(X_sm_tl, y_sm_tl)\n",
    "\n",
    "print(\"Best Parameters:\", gs_grb.best_params_)\n",
    "print(\"Best Precision Score:\", gs_grb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bb445f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 121 1004]\n",
      " [  64  564]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.11      0.18      1125\n",
      "           1       0.36      0.90      0.51       628\n",
      "\n",
      "    accuracy                           0.39      1753\n",
      "   macro avg       0.51      0.50      0.35      1753\n",
      "weighted avg       0.55      0.39      0.30      1753\n",
      "\n",
      "Precision: 0.3596938775510204\n",
      "Accuracy: 0.3907586993725043\n",
      "AUC: 0.5153949044585987\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tuned_grb= gs_grb.best_estimator_\n",
    "train_and_evaluate_model(tuned_grb, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9496232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29ff8e08",
   "metadata": {},
   "source": [
    "--- XGB ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8943f6b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 121 1004]\n",
      " [  64  564]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.11      0.18      1125\n",
      "           1       0.36      0.90      0.51       628\n",
      "\n",
      "    accuracy                           0.39      1753\n",
      "   macro avg       0.51      0.50      0.35      1753\n",
      "weighted avg       0.55      0.39      0.30      1753\n",
      "\n",
      "Precision: 0.3596938775510204\n",
      "Accuracy: 0.3907586993725043\n",
      "AUC: 0.5153949044585987\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb= XGBClassifier(random_state=15)\n",
    "train_and_evaluate_model(xgb, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da093569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best Parameters: {'learning_rate': 0.1}\n",
      "Best Precision Score: 0.671251297680209\n",
      "[[ 121 1004]\n",
      " [  64  564]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.11      0.18      1125\n",
      "           1       0.36      0.90      0.51       628\n",
      "\n",
      "    accuracy                           0.39      1753\n",
      "   macro avg       0.51      0.50      0.35      1753\n",
      "weighted avg       0.55      0.39      0.30      1753\n",
      "\n",
      "Precision: 0.3596938775510204\n",
      "Accuracy: 0.3907586993725043\n",
      "AUC: 0.5153949044585987\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "params_XGBoost= {'learning_rate': [0.01, 0.1, 1.0]}\n",
    "\n",
    "gs_xgb= GridSearchCV(estimator= xgb, param_grid= params_XGBoost, cv= 5, scoring= 'precision', n_jobs= -1, verbose= 2)\n",
    "gs_xgb.fit(X_sm_tl, y_sm_tl)\n",
    "\n",
    "print(\"Best Parameters:\", gs_xgb.best_params_)\n",
    "print(\"Best Precision Score:\", gs_xgb.best_score_)\n",
    "\n",
    "tuned_xgb= gs_xgb.best_estimator_\n",
    "train_and_evaluate_model(tuned_xgb, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bd651d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe4ddc2b",
   "metadata": {},
   "source": [
    "--- LGBM ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a1effa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2511, number of negative: 2511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 20\n",
      "[LightGBM] [Info] Number of data points in the train set: 5022, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[[ 121 1004]\n",
      " [  64  564]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.11      0.18      1125\n",
      "           1       0.36      0.90      0.51       628\n",
      "\n",
      "    accuracy                           0.39      1753\n",
      "   macro avg       0.51      0.50      0.35      1753\n",
      "weighted avg       0.55      0.39      0.30      1753\n",
      "\n",
      "Precision: 0.3596938775510204\n",
      "Accuracy: 0.3907586993725043\n",
      "AUC: 0.5153949044585987\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgm= LGBMClassifier(random_state=15)\n",
    "train_and_evaluate_model(lgm, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9dec891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Number of positive: 2511, number of negative: 2511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2253\n",
      "[LightGBM] [Info] Number of data points in the train set: 5022, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Best Parameters: {'learning_rate': 0.1, 'min_data_in_leaf': 30, 'num_leaves': 31, 'reg_alpha': 0.5}\n",
      "Best Precision Score: 0.6695895316370789\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Number of positive: 2511, number of negative: 2511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20\n",
      "[LightGBM] [Info] Number of data points in the train set: 5022, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[[ 121 1004]\n",
      " [  64  564]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.11      0.18      1125\n",
      "           1       0.36      0.90      0.51       628\n",
      "\n",
      "    accuracy                           0.39      1753\n",
      "   macro avg       0.51      0.50      0.35      1753\n",
      "weighted avg       0.55      0.39      0.30      1753\n",
      "\n",
      "Precision: 0.3596938775510204\n",
      "Accuracy: 0.3907586993725043\n",
      "AUC: 0.5153949044585987\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "params_LGB= {'learning_rate': [0.001, 0.01, 0.1, 1.0],\n",
    "             'num_leaves': [31, 127],\n",
    "             'reg_alpha': [0.1, 0.5],\n",
    "             'min_data_in_leaf': [30, 50, 100, 300, 400]}\n",
    "\n",
    "gs_lgm= GridSearchCV(estimator= lgm, param_grid= params_LGB, cv=5, scoring='precision', n_jobs=-1, verbose=2)\n",
    "gs_lgm.fit(X_sm_tl, y_sm_tl)\n",
    "\n",
    "print(\"Best Parameters:\", gs_lgm.best_params_)\n",
    "print(\"Best Precision Score:\", gs_lgm.best_score_)\n",
    "\n",
    "tuned_lgm= gs_lgm.best_estimator_\n",
    "train_and_evaluate_model(tuned_lgm, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ae9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a7670df",
   "metadata": {},
   "source": [
    "--- CatBoost ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfa1cef8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 121 1004]\n",
      " [  64  564]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.11      0.18      1125\n",
      "           1       0.36      0.90      0.51       628\n",
      "\n",
      "    accuracy                           0.39      1753\n",
      "   macro avg       0.51      0.50      0.35      1753\n",
      "weighted avg       0.55      0.39      0.30      1753\n",
      "\n",
      "Precision: 0.3596938775510204\n",
      "Accuracy: 0.3907586993725043\n",
      "AUC: 0.5153949044585987\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat= CatBoostClassifier(learning_rate= 0.1, depth= 6, iterations= 100, random_state= 15, verbose= 0)\n",
    "train_and_evaluate_model(cat, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8d322e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0af2c970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Parameters: {'depth': 5, 'iterations': 100, 'learning_rate': 0.1}\n",
      "Best Precision Score: 0.6641814124189656\n",
      "[[ 121 1004]\n",
      " [  64  564]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.11      0.18      1125\n",
      "           1       0.36      0.90      0.51       628\n",
      "\n",
      "    accuracy                           0.39      1753\n",
      "   macro avg       0.51      0.50      0.35      1753\n",
      "weighted avg       0.55      0.39      0.30      1753\n",
      "\n",
      "Precision: 0.3596938775510204\n",
      "Accuracy: 0.3907586993725043\n",
      "AUC: 0.5153949044585987\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "params_CatBoost= {\n",
    "                  'depth': [3,5,10],\n",
    "                  'learning_rate' : [0.01,0.1,1],\n",
    "                  'iterations' : [5,10,50,100]\n",
    "                 }\n",
    "\n",
    "gs_cat= GridSearchCV(estimator= cat, param_grid= params_CatBoost, cv=5, scoring='precision', n_jobs=-1, verbose=2)\n",
    "gs_cat.fit(X_sm_tl, y_sm_tl)\n",
    "\n",
    "print(\"Best Parameters:\", gs_cat.best_params_)\n",
    "print(\"Best Precision Score:\", gs_cat.best_score_)\n",
    "\n",
    "tuned_cat= gs_cat.best_estimator_\n",
    "train_and_evaluate_model(tuned_cat, X_sm_tl_selected, y_sm_tl, X_sm_tl_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44677a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "770d3077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr= lr.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_lr= lr.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "y_pred_dt= dt.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_dt= dt.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "y_pred_tuned_dt= tuned_dt.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_dt= tuned_dt.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "y_pred_knn= knn.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_knn= knn.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "y_pred_tuned_knn= tuned_knn.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_knn= tuned_knn.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "y_pred_nb= nb.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_nb= nb.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "y_pred_svc= svc.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_svc= svc.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "y_pred_rf= rf.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_rf= rf.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "y_pred_tuned_rf= tuned_rf.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_rf= tuned_rf.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "y_pred_ada= ada.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_ada= ada.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "y_pred_tuned_ada= tuned_ada.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_ada= tuned_ada.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "y_pred_grb= grb.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_grb= grb.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "y_pred_tuned_grb= tuned_grb.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_grb= tuned_grb.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "y_pred_xgb= xgb.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_xgb= xgb.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "y_pred_tuned_xgb= tuned_xgb.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_xgb= tuned_xgb.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "y_pred_lgm= lgm.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_lgm= lgm.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "y_pred_tuned_lgm= tuned_lgm.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_lgm= tuned_lgm.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "y_pred_cat= cat.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_cat= cat.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "y_pred_tuned_cat= tuned_cat.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_cat= tuned_cat.predict_proba(X_sm_tl_test_selected)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57855ee",
   "metadata": {},
   "source": [
    "--- Visualisation ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9984fadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Precision Score\n",
      "0          Logistic Regression Precision:         0.379085\n",
      "5                   GaussianNB Precision:         0.379085\n",
      "11            GradientBoosting Precision:         0.359694\n",
      "17                    CatBoost Precision:         0.359694\n",
      "16                  Tuned LGBM Precision:         0.359694\n",
      "15                        LGBM Precision:         0.359694\n",
      "14                   Tuned XGB Precision:         0.359694\n",
      "13                         XGB Precision:         0.359694\n",
      "12      Tuned GradientBoosting Precision:         0.359694\n",
      "18              Tuned CatBoost Precision:         0.359694\n",
      "1                Decision Tree Precision:         0.359694\n",
      "8          Tuned Random Forest Precision:         0.359694\n",
      "7                Random Forest Precision:         0.359694\n",
      "6                          SVM Precision:         0.359694\n",
      "2          Tuned Decision Tree Precision:         0.359694\n",
      "10              Tuned AdaBoost Precision:         0.359504\n",
      "9                     AdaBoost Precision:         0.359504\n",
      "4   Tuned KNeighborsClassifier Precision:         0.000000\n",
      "3         KNeighborsClassifier Precision:         0.000000\n"
     ]
    }
   ],
   "source": [
    "precision_scores= {\n",
    "                    'Logistic Regression Precision:': precision_score(y_test, y_pred_lr, zero_division= 0),\n",
    "                    'Decision Tree Precision:': precision_score(y_test, y_pred_dt, zero_division= 0),\n",
    "                    'Tuned Decision Tree Precision:': precision_score(y_test, y_pred_tuned_dt, zero_division= 0),\n",
    "                    'KNeighborsClassifier Precision:': precision_score(y_test, y_pred_knn, zero_division= 0),\n",
    "                    'Tuned KNeighborsClassifier Precision:': precision_score(y_test, y_pred_tuned_knn, zero_division= 0),\n",
    "                    'GaussianNB Precision:': precision_score(y_test, y_pred_nb, zero_division= 0),\n",
    "                    'SVM Precision:': precision_score(y_test, y_pred_svc, zero_division= 0),\n",
    "                    'Random Forest Precision:': precision_score(y_test, y_pred_rf, zero_division= 0),\n",
    "                    'Tuned Random Forest Precision:': precision_score(y_test, y_pred_tuned_rf, zero_division= 0),\n",
    "                    'AdaBoost Precision:': precision_score(y_test, y_pred_ada, zero_division= 0),\n",
    "                    'Tuned AdaBoost Precision:': precision_score(y_test, y_pred_tuned_ada, zero_division= 0),\n",
    "                    'GradientBoosting Precision:': precision_score(y_test, y_pred_grb, zero_division= 0),\n",
    "                    'Tuned GradientBoosting Precision:': precision_score(y_test, y_pred_tuned_grb, zero_division= 0),\n",
    "                    'XGB Precision:': precision_score(y_test, y_pred_xgb, zero_division= 0),\n",
    "                    'Tuned XGB Precision:': precision_score(y_test, y_pred_tuned_xgb, zero_division= 0),\n",
    "                    'LGBM Precision:': precision_score(y_test, y_pred_lgm, zero_division= 0),\n",
    "                    'Tuned LGBM Precision:': precision_score(y_test, y_pred_tuned_lgm, zero_division= 0),\n",
    "                    'CatBoost Precision:': precision_score(y_test, y_pred_cat, zero_division= 0),\n",
    "                    'Tuned CatBoost Precision:': precision_score(y_test, y_pred_tuned_cat, zero_division= 0)\n",
    "                  }\n",
    "\n",
    "be_precision= pd.DataFrame(list(precision_scores.items()), columns= ['Model', 'Precision Score'])\n",
    "be_precision= be_precision.sort_values(by= 'Precision Score', ascending=False)\n",
    "print(be_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "209b0ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Model  Accuracy Score\n",
      "3         KNeighborsClassifier Accuracy:        0.641757\n",
      "4   Tuned KNeighborsClassifier Accuracy:        0.641757\n",
      "0          Logistic Regression Accuracy:        0.536224\n",
      "5                   GaussianNB Accuracy:        0.536224\n",
      "10              Tuned AdaBoost Accuracy:        0.447804\n",
      "9                     AdaBoost Accuracy:        0.447804\n",
      "6                          SVM Accuracy:        0.390759\n",
      "7                Random Forest Accuracy:        0.390759\n",
      "8          Tuned Random Forest Accuracy:        0.390759\n",
      "1                Decision Tree Accuracy:        0.390759\n",
      "2          Tuned Decision Tree Accuracy:        0.390759\n",
      "11            GradientBoosting Accuracy:        0.390759\n",
      "12      Tuned GradientBoosting Accuracy:        0.390759\n",
      "13                         XGB Accuracy:        0.390759\n",
      "14                   Tuned XGB Accuracy:        0.390759\n",
      "15                        LGBM Accuracy:        0.390759\n",
      "16                  Tuned LGBM Accuracy:        0.390759\n",
      "17                    CatBoost Accuracy:        0.390759\n",
      "18              Tuned CatBoost Accuracy:        0.390759\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores= {\n",
    "                    'Logistic Regression Accuracy:': accuracy_score(y_test, y_pred_lr),\n",
    "                    'Decision Tree Accuracy:': accuracy_score(y_test, y_pred_dt),\n",
    "                    'Tuned Decision Tree Accuracy:': accuracy_score(y_test, y_pred_tuned_dt),\n",
    "                    'KNeighborsClassifier Accuracy:': accuracy_score(y_test, y_pred_knn),\n",
    "                    'Tuned KNeighborsClassifier Accuracy:': accuracy_score(y_test, y_pred_tuned_knn),\n",
    "                    'GaussianNB Accuracy:': accuracy_score(y_test, y_pred_nb),\n",
    "                    'SVM Accuracy:': accuracy_score(y_test, y_pred_svc),\n",
    "                    'Random Forest Accuracy:': accuracy_score(y_test, y_pred_rf),\n",
    "                    'Tuned Random Forest Accuracy:': accuracy_score(y_test, y_pred_tuned_rf),\n",
    "                    'AdaBoost Accuracy:': accuracy_score(y_test, y_pred_ada),\n",
    "                    'Tuned AdaBoost Accuracy:': accuracy_score(y_test, y_pred_tuned_ada),\n",
    "                    'GradientBoosting Accuracy:': accuracy_score(y_test, y_pred_grb),\n",
    "                    'Tuned GradientBoosting Accuracy:': accuracy_score(y_test, y_pred_tuned_grb),\n",
    "                    'XGB Accuracy:': accuracy_score(y_test, y_pred_xgb),\n",
    "                    'Tuned XGB Accuracy:': accuracy_score(y_test, y_pred_tuned_xgb),\n",
    "                    'LGBM Accuracy:': accuracy_score(y_test, y_pred_lgm),\n",
    "                    'Tuned LGBM Accuracy:': accuracy_score(y_test, y_pred_tuned_lgm),\n",
    "                    'CatBoost Accuracy:': accuracy_score(y_test, y_pred_cat),\n",
    "                    'Tuned CatBoost Accuracy:': accuracy_score(y_test, y_pred_tuned_cat)\n",
    "                  }\n",
    "\n",
    "be_accuracy= pd.DataFrame(list(accuracy_scores.items()), columns= ['Model', 'Accuracy Score'])\n",
    "be_accuracy= be_accuracy.sort_values(by= 'Accuracy Score', ascending=False)\n",
    "print(be_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7f99f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Model  AUC Score\n",
      "6                          SVM AUC:   0.523173\n",
      "0          Logistic Regression AUC:   0.515395\n",
      "10              Tuned AdaBoost AUC:   0.515395\n",
      "17                    CatBoost AUC:   0.515395\n",
      "16                  Tuned LGBM AUC:   0.515395\n",
      "15                        LGBM AUC:   0.515395\n",
      "14                   Tuned XGB AUC:   0.515395\n",
      "13                         XGB AUC:   0.515395\n",
      "12      Tuned GradientBoosting AUC:   0.515395\n",
      "11            GradientBoosting AUC:   0.515395\n",
      "9                     AdaBoost AUC:   0.515395\n",
      "1                Decision Tree AUC:   0.515395\n",
      "8          Tuned Random Forest AUC:   0.515395\n",
      "7                Random Forest AUC:   0.515395\n",
      "5                   GaussianNB AUC:   0.515395\n",
      "2          Tuned Decision Tree AUC:   0.515395\n",
      "18              Tuned CatBoost AUC:   0.515395\n",
      "4   Tuned KNeighborsClassifier AUC:   0.500000\n",
      "3         KNeighborsClassifier AUC:   0.500000\n"
     ]
    }
   ],
   "source": [
    "auc_scores= {\n",
    "                    'Logistic Regression AUC:': roc_auc_score(y_test, y_pred_prob_lr),\n",
    "                    'Decision Tree AUC:': roc_auc_score(y_test, y_pred_prob_dt),\n",
    "                    'Tuned Decision Tree AUC:': roc_auc_score(y_test, y_pred_prob_tuned_dt),\n",
    "                    'KNeighborsClassifier AUC:': roc_auc_score(y_test, y_pred_prob_knn),\n",
    "                    'Tuned KNeighborsClassifier AUC:': roc_auc_score(y_test, y_pred_prob_tuned_knn),\n",
    "                    'GaussianNB AUC:': roc_auc_score(y_test, y_pred_prob_nb),\n",
    "                    'SVM AUC:': roc_auc_score(y_test, y_pred_prob_svc),\n",
    "                    'Random Forest AUC:': roc_auc_score(y_test, y_pred_prob_rf),\n",
    "                    'Tuned Random Forest AUC:': roc_auc_score(y_test, y_pred_prob_tuned_rf),\n",
    "                    'AdaBoost AUC:': roc_auc_score(y_test, y_pred_prob_ada),\n",
    "                    'Tuned AdaBoost AUC:': roc_auc_score(y_test, y_pred_prob_tuned_ada),\n",
    "                    'GradientBoosting AUC:': roc_auc_score(y_test, y_pred_prob_grb),\n",
    "                    'Tuned GradientBoosting AUC:': roc_auc_score(y_test, y_pred_prob_tuned_grb),\n",
    "                    'XGB AUC:': roc_auc_score(y_test, y_pred_prob_xgb),\n",
    "                    'Tuned XGB AUC:': roc_auc_score(y_test, y_pred_prob_tuned_xgb),\n",
    "                    'LGBM AUC:': roc_auc_score(y_test, y_pred_prob_lgm),\n",
    "                    'Tuned LGBM AUC:': roc_auc_score(y_test, y_pred_prob_tuned_lgm),\n",
    "                    'CatBoost AUC:': roc_auc_score(y_test, y_pred_prob_cat),\n",
    "                    'Tuned CatBoost AUC:': roc_auc_score(y_test, y_pred_prob_tuned_cat)\n",
    "                  }\n",
    "\n",
    "be_auc= pd.DataFrame(list(auc_scores.items()), columns= ['Model', 'AUC Score'])\n",
    "be_auc= be_auc.sort_values(by= 'AUC Score', ascending=False)\n",
    "print(be_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2ac15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dee7d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d9919c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011f3570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
