{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f807d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df= pd.read_csv('C://Users//User//Desktop//MSc Westminster//Dissertation//DataSets//Heart_Attack_Prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d77e531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=df.columns\n",
    "\n",
    "for column in columns:\n",
    "    if df[column].dtype==\"int32\":\n",
    "        df[column]=df[column].astype(\"int16\")\n",
    "    elif df[column].dtype==\"float64\":\n",
    "        df[column]=df[column].astype(\"float16\")\n",
    "    elif df[column].dtype==\"object\":\n",
    "        df[column]=df[column].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfa3c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex']= df['Sex'].map({'Female': 0, 'Male': 1})\n",
    "df['Sex']= pd.to_numeric(df['Sex'])\n",
    "\n",
    "df['Diet']= df['Diet'].map({'Healthy': 0, 'Average': 1, 'Unhealthy':2})\n",
    "df['Diet']= pd.to_numeric(df['Diet'])\n",
    "\n",
    "df[['HBP', 'LBP']]= df['Blood Pressure'].str.split('/', expand= True)\n",
    "df['HBP']= pd.to_numeric(df['HBP'])\n",
    "df['LBP']= pd.to_numeric(df['LBP'])\n",
    "\n",
    "df['Diabetes'] = df['Diabetes'].map({0: 1, 1: 0})\n",
    "\n",
    "df['Exercise Hours Per Week']= round(df['Exercise Hours Per Week'], 0)\n",
    "\n",
    "df['Sedentary Hours Per Day']= round(df['Sedentary Hours Per Day'], 0)\n",
    "\n",
    "df['Income']= round(df['Income'], 0)\n",
    "\n",
    "df['BMI']= round(df['BMI'], 0)\n",
    "\n",
    "df = df.drop(columns=['Patient ID', 'Blood Pressure', 'Country', 'Continent', 'Hemisphere'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b65ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "151027e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop(['Heart Attack Risk'], axis= 1)\n",
    "y= df['Heart Attack Risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e49eb021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2, random_state= 15, stratify= y)\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler= RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train= scaler.transform(X_train)\n",
    "X_test= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e9e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "sm= ClusterCentroids(random_state= 15, estimator= KMeans(n_init= 10))\n",
    "tl= SMOTE(random_state= 15)\n",
    "\n",
    "X_sm, y_sm= sm.fit_resample(X_train, y_train)\n",
    "X_sm_tl, y_sm_tl= tl.fit_resample(X_sm, y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0826cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "482869c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "selector= SelectKBest(score_func= f_classif, k= 10)\n",
    "X_sm_tl_selected= selector.fit_transform(X_sm_tl, y_sm_tl)\n",
    "X_sm_tl_test_selected= selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "685662c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:  Index(['Age', 'Sex', 'Cholesterol', 'Heart Rate', 'Diabetes', 'Smoking',\n",
      "       'Stress Level', 'Physical Activity Days Per Week',\n",
      "       'Sleep Hours Per Day', 'HBP'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "feature_names= X.columns\n",
    "selected_indices= selector.get_support(indices=True)\n",
    "selected_features= feature_names[selected_indices]\n",
    "print(\"Selected Features: \", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00333eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba518df9",
   "metadata": {},
   "source": [
    "--- DecisionTreeClassifier ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38c4309f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[485 640]\n",
      " [280 348]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.43      0.51      1125\n",
      "           1       0.35      0.55      0.43       628\n",
      "\n",
      "    accuracy                           0.48      1753\n",
      "   macro avg       0.49      0.49      0.47      1753\n",
      "weighted avg       0.53      0.48      0.48      1753\n",
      "\n",
      "Precision: 0.3522267206477733\n",
      "Accuracy: 0.47518539646320596\n",
      "AUC: 0.4926256192498231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, roc_auc_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt= DecisionTreeClassifier(random_state=15)\n",
    "dt.fit(X_sm_tl_selected, y_sm_tl)\n",
    "y_pred_dt= dt.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_dt= dt.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_dt, labels= dt.classes_)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_dt, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_dt, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_dt))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb610b3b",
   "metadata": {},
   "source": [
    "--- Tuned - DecisionTreeClassifier ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d17b1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[419 706]\n",
      " [221 407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.37      0.47      1125\n",
      "           1       0.37      0.65      0.47       628\n",
      "\n",
      "    accuracy                           0.47      1753\n",
      "   macro avg       0.51      0.51      0.47      1753\n",
      "weighted avg       0.55      0.47      0.47      1753\n",
      "\n",
      "Precision: 0.3656783468104223\n",
      "Accuracy: 0.47119224187107817\n",
      "AUC: 0.5109193205944799\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid= {\n",
    "             'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "             'min_samples_split': [2, 10, 20],\n",
    "             'min_samples_leaf': [1, 5, 10],\n",
    "             'max_features': [None, 'sqrt', 'log2'],\n",
    "             'criterion': ['gini', 'entropy']\n",
    "            }\n",
    "\n",
    "gs_dt= GridSearchCV(estimator= dt, param_grid= param_grid, cv= 5, scoring= 'precision')\n",
    "gs_dt.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "tuned_dt= gs_dt.best_estimator_\n",
    "y_pred_tuned_dt= tuned_dt.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_dt= tuned_dt.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_dt, labels= tuned_dt.classes_)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_tuned_dt, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_dt, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_dt))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641ddd7",
   "metadata": {},
   "source": [
    "--- Tuned - DecisionTreeClassifier 1 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77e99f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[483 642]\n",
      " [249 379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.43      0.52      1125\n",
      "           1       0.37      0.60      0.46       628\n",
      "\n",
      "    accuracy                           0.49      1753\n",
      "   macro avg       0.52      0.52      0.49      1753\n",
      "weighted avg       0.56      0.49      0.50      1753\n",
      "\n",
      "Precision: 0.3712047012732615\n",
      "Accuracy: 0.4917284654877353\n",
      "AUC: 0.5164182590233546\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'max_features': [None, 'sqrt', 'log2', 0.5, 0.75],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'class_weight': [None, 'balanced', {0: 1, 1: 2}, {0: 1, 1: 3}, {0: 1, 1: 5}]\n",
    "}\n",
    "\n",
    "gs_dt= GridSearchCV(estimator= dt, param_grid= param_grid, cv= 5, scoring= 'precision', n_jobs= -1)\n",
    "gs_dt.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "tuned_dt1= gs_dt.best_estimator_\n",
    "y_pred_tuned_dt1= tuned_dt1.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_dt1= tuned_dt1.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_dt1, labels= tuned_dt1.classes_)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_tuned_dt1, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_dt1, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_dt1))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_dt1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486ad127",
   "metadata": {},
   "source": [
    "--- Tuned - RandomizedSearchCV 2 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cad2901f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[483 642]\n",
      " [249 379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.43      0.52      1125\n",
      "           1       0.37      0.60      0.46       628\n",
      "\n",
      "    accuracy                           0.49      1753\n",
      "   macro avg       0.52      0.52      0.49      1753\n",
      "weighted avg       0.56      0.49      0.50      1753\n",
      "\n",
      "Precision: 0.3712047012732615\n",
      "Accuracy: 0.4917284654877353\n",
      "AUC: 0.5164182590233546\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_dist = {\n",
    "    'max_depth': [None] + list(range(5, 51, 5)),\n",
    "    'min_samples_split': randint(2, 21),\n",
    "    'min_samples_leaf': randint(1, 21),\n",
    "    'max_features': [None, 'sqrt', 'log2', 0.5, 0.75],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'class_weight': [None, 'balanced', {0: 1, 1: 2}, {0: 1, 1: 3}, {0: 1, 1: 5}]\n",
    "}\n",
    "\n",
    "rs_dt = RandomizedSearchCV(estimator= dt, param_distributions= param_dist, n_iter= 100, cv= 5, scoring= 'precision', random_state= 15, n_jobs= -1)\n",
    "gs_dt.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "tuned_dt2= gs_dt.best_estimator_\n",
    "y_pred_tuned_dt2= tuned_dt2.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_dt2= tuned_dt2.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_dt2, labels= tuned_dt2.classes_)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_tuned_dt2, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_dt2, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_dt2))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_dt2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ab6d4c",
   "metadata": {},
   "source": [
    "--- Tuned - DecisionTreeClassifier 3 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94d074fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[483 642]\n",
      " [249 379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.43      0.52      1125\n",
      "           1       0.37      0.60      0.46       628\n",
      "\n",
      "    accuracy                           0.49      1753\n",
      "   macro avg       0.52      0.52      0.49      1753\n",
      "weighted avg       0.56      0.49      0.50      1753\n",
      "\n",
      "Precision: 0.3712047012732615\n",
      "Accuracy: 0.4917284654877353\n",
      "AUC: 0.5164182590233546\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "best_params = tuned_dt2.get_params()\n",
    "param_grid = {\n",
    "    'max_depth': [best_params['max_depth'] - 5, best_params['max_depth'], best_params['max_depth'] + 5] if best_params['max_depth'] is not None else [None, 5, 10],\n",
    "    'min_samples_split': [max(2, best_params['min_samples_split'] - 5), best_params['min_samples_split'], best_params['min_samples_split'] + 5],\n",
    "    'min_samples_leaf': [max(1, best_params['min_samples_leaf'] - 2), best_params['min_samples_leaf'], best_params['min_samples_leaf'] + 2],\n",
    "    'max_features': [best_params['max_features']],\n",
    "    'criterion': [best_params['criterion']],\n",
    "    'class_weight': [best_params['class_weight']]\n",
    "}\n",
    "\n",
    "gs_dt= GridSearchCV(estimator= dt, param_grid= param_grid, cv= 5, scoring= 'precision', n_jobs= -1)\n",
    "gs_dt.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "tuned_dt3= gs_dt.best_estimator_\n",
    "y_pred_tuned_dt3= tuned_dt3.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_dt3= tuned_dt3.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_dt3, labels= tuned_dt3.classes_)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_tuned_dt3, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_dt3, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_dt3))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_dt3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9040c784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb8c7fce",
   "metadata": {},
   "source": [
    "--- GaussianNB ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dbd7832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[346 779]\n",
      " [179 449]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.31      0.42      1125\n",
      "           1       0.37      0.71      0.48       628\n",
      "\n",
      "    accuracy                           0.45      1753\n",
      "   macro avg       0.51      0.51      0.45      1753\n",
      "weighted avg       0.55      0.45      0.44      1753\n",
      "\n",
      "Precision: 0.36563517915309446\n",
      "Accuracy: 0.4535082715345123\n",
      "AUC: 0.5039207360226469\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb= GaussianNB()\n",
    "nb.fit(X_sm_tl_selected, y_sm_tl)\n",
    "y_pred_nb= nb.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_nb= nb.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_nb, labels= nb.classes_)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_nb, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_nb, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_nb))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56176147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1eee9f63",
   "metadata": {},
   "source": [
    "--- Tuned GaussianNB ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "270085ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[517 608]\n",
      " [288 340]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.46      0.54      1125\n",
      "           1       0.36      0.54      0.43       628\n",
      "\n",
      "    accuracy                           0.49      1753\n",
      "   macro avg       0.50      0.50      0.48      1753\n",
      "weighted avg       0.54      0.49      0.50      1753\n",
      "\n",
      "Precision: 0.35864978902953587\n",
      "Accuracy: 0.48887621220764405\n",
      "AUC: 0.4991309271054494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid= {'var_smoothing': np.logspace(-9, 0, 100)}\n",
    "\n",
    "gs_nb= GridSearchCV(estimator= nb, param_grid= param_grid, cv= 5, scoring= 'precision', n_jobs= -1)\n",
    "gs_nb.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "tuned_nb= gs_nb.best_estimator_\n",
    "y_pred_tuned_nb= tuned_nb.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_nb= tuned_nb.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_nb, labels= tuned_nb1.classes_)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_tuned_nb, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_nb, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_nb))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d46c3e8",
   "metadata": {},
   "source": [
    "--- Tuned GaussianNB 1 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "673a92b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 123 1002]\n",
      " [  67  561]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.11      0.19      1125\n",
      "           1       0.36      0.89      0.51       628\n",
      "\n",
      "    accuracy                           0.39      1753\n",
      "   macro avg       0.50      0.50      0.35      1753\n",
      "weighted avg       0.54      0.39      0.30      1753\n",
      "\n",
      "Precision: 0.35892514395393477\n",
      "Accuracy: 0.390188248716486\n",
      "AUC: 0.5038145789101203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'var_smoothing': np.logspace(-9, 0, 100),\n",
    "    'priors': [[0.3, 0.7], [0.2, 0.8], [0.1, 0.9]]\n",
    "}\n",
    "\n",
    "gs_nb= GridSearchCV(estimator= nb, param_grid= param_grid, cv= 5, scoring= 'precision', n_jobs= -1)\n",
    "gs_nb.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "tuned_nb1= gs_nb.best_estimator_\n",
    "y_pred_tuned_nb1= tuned_nb1.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_nb2= tuned_nb1.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_nb1, labels= tuned_nb2.classes_)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_tuned_nb1, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_nb1, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_nb1))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_nb1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d43ea29",
   "metadata": {},
   "source": [
    "--- Tuned GaussianNB RandomizedSearchCV 2 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "282cf414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'priors': [0.3, 0.7], 'var_smoothing': 0.003956967935062682}\n",
      "Confusion Matrix:\n",
      " [[ 123 1002]\n",
      " [  67  561]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.11      0.19      1125\n",
      "           1       0.36      0.89      0.51       628\n",
      "\n",
      "    accuracy                           0.39      1753\n",
      "   macro avg       0.50      0.50      0.35      1753\n",
      "weighted avg       0.54      0.39      0.30      1753\n",
      "\n",
      "Precision: 0.35892514395393477\n",
      "Accuracy: 0.390188248716486\n",
      "AUC: 0.5038273177636234\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "param_dist = {\n",
    "    'var_smoothing': loguniform(1e-9, 1e0),\n",
    "    'priors': [[0.3, 0.7], [0.2, 0.8], [0.1, 0.9]]\n",
    "}\n",
    "\n",
    "rs_nb = RandomizedSearchCV(estimator=nb, param_distributions=param_dist, n_iter=100, cv=5, scoring='precision', random_state=15, n_jobs=-1)\n",
    "rs_nb.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "tuned_nb2= rs_nb.best_estimator_\n",
    "y_pred_tuned_nb2= tuned_nb2.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_nb2= tuned_nb2.predict_proba(X_sm_tl_test_selected)[:, 1]\n",
    "\n",
    "print(\"Best parameters:\", rs_nb.best_params_)\n",
    "cm = confusion_matrix(y_test, y_pred_tuned_nb2, labels=tuned_nb2.classes_)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(classification_report(y_test, y_pred_tuned_nb2, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_nb2, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_nb2))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_nb2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd49e5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cc62ec3",
   "metadata": {},
   "source": [
    "--- SVM ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446f144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f655fef3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[510 615]\n",
      " [268 360]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.45      0.54      1125\n",
      "           1       0.37      0.57      0.45       628\n",
      "\n",
      "    accuracy                           0.50      1753\n",
      "   macro avg       0.51      0.51      0.49      1753\n",
      "weighted avg       0.55      0.50      0.50      1753\n",
      "\n",
      "Precision: 0.36923076923076925\n",
      "Accuracy: 0.49629207073588133\n",
      "AUC: 0.5207954706298655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc= SVC(kernel= 'rbf',probability= True, gamma= 1, random_state=15)\n",
    "svc.fit(X_sm_tl_selected, y_sm_tl)\n",
    "y_pred_svc= svc.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_svc= svc.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_svc, labels= svc.classes_)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_svc, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_svc, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_svc))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323d913c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b28e5ae",
   "metadata": {},
   "source": [
    "--- Tuned SVM ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b64e4268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[510 615]\n",
      " [268 360]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.35      0.45      1125\n",
      "           1       0.36      0.65      0.46       628\n",
      "\n",
      "    accuracy                           0.45      1753\n",
      "   macro avg       0.50      0.50      0.45      1753\n",
      "weighted avg       0.54      0.45      0.45      1753\n",
      "\n",
      "Precision: 0.356140350877193\n",
      "Accuracy: 0.45464917284654877\n",
      "AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "gs_svc= GridSearchCV(estimator= svc, param_grid= param_grid, cv= 5, scoring= 'precision', n_jobs= -1)\n",
    "gs_svc.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "tuned_svc= gs_svc.best_estimator_\n",
    "y_pred_tuned_svc= tuned_svc.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_svc= tuned_svc.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_svc, labels= tuned_svc.classes_)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_tuned_svc, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_svc, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_svc))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dd4f85",
   "metadata": {},
   "source": [
    "--- Tuned SVM 1 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b15bd8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[426 699]\n",
      " [244 384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.38      0.47      1125\n",
      "           1       0.35      0.61      0.45       628\n",
      "\n",
      "    accuracy                           0.46      1753\n",
      "   macro avg       0.50      0.50      0.46      1753\n",
      "weighted avg       0.54      0.46      0.47      1753\n",
      "\n",
      "Precision: 0.3545706371191136\n",
      "Accuracy: 0.4620650313747861\n",
      "AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': np.logspace(-2, 2, 10),\n",
    "    'gamma': np.logspace(-3, 1, 10),\n",
    "    'kernel': ['rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "gs_svc= GridSearchCV(estimator= svc, param_grid= param_grid, cv= 5, scoring= 'precision', n_jobs= -1)\n",
    "gs_svc.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "tuned_svc1= gs_svc.best_estimator_\n",
    "y_pred_tuned_svc1= tuned_svc1.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_svc1= tuned_svc1.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_svc1, labels= tuned_svc1.classes_)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_tuned_svc1, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_svc1, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_svc1))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_svc1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbca00f1",
   "metadata": {},
   "source": [
    "--- Tuned SVM - RandomizedSearchCV 2 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc774e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[457 668]\n",
      " [241 387]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.41      0.50      1125\n",
      "           1       0.37      0.62      0.46       628\n",
      "\n",
      "    accuracy                           0.48      1753\n",
      "   macro avg       0.51      0.51      0.48      1753\n",
      "weighted avg       0.55      0.48      0.49      1753\n",
      "\n",
      "Precision: 0.36682464454976305\n",
      "Accuracy: 0.4814603536794067\n",
      "AUC: 0.5102788393489031\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import expon\n",
    "param_dist= {\n",
    "    'C': expon(scale=100),\n",
    "    'gamma': expon(scale=.1),\n",
    "    'kernel': ['rbf', 'sigmoid'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "rs_svc= RandomizedSearchCV(estimator= svc, param_distributions= param_dist, n_iter= 100, cv= 5, scoring= 'precision', random_state= 15,  n_jobs= -1)\n",
    "rs_svc.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "tuned_svc2= rs_svc.best_estimator_\n",
    "y_pred_tuned_svc2= tuned_svc2.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_svc2= tuned_svc2.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_svc2, labels= tuned_svc1.classes_)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_tuned_svc2, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_svc2, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_svc2))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_svc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629f2f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe4ddc2b",
   "metadata": {},
   "source": [
    "--- LGBM ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a1effa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2511, number of negative: 2511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1171\n",
      "[LightGBM] [Info] Number of data points in the train set: 5022, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[[258 867]\n",
      " [133 495]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.23      0.34      1125\n",
      "           1       0.36      0.79      0.50       628\n",
      "\n",
      "    accuracy                           0.43      1753\n",
      "   macro avg       0.51      0.51      0.42      1753\n",
      "weighted avg       0.55      0.43      0.40      1753\n",
      "\n",
      "Precision: 0.3634361233480176\n",
      "Accuracy: 0.4295493439817456\n",
      "AUC: 0.5105024769992923\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgm= LGBMClassifier(random_state=15)\n",
    "lgm.fit(X_sm_tl_selected, y_sm_tl)\n",
    "y_pred_lgm= lgm.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_lgm= lgm.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_lgm, labels= lgm.classes_)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_lgm, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_lgm, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_lgm))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_lgm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9dec891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Info] Number of positive: 2511, number of negative: 2511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1171\n",
      "[LightGBM] [Info] Number of data points in the train set: 5022, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400\n",
      "[[317 808]\n",
      " [167 461]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.28      0.39      1125\n",
      "           1       0.36      0.73      0.49       628\n",
      "\n",
      "    accuracy                           0.44      1753\n",
      "   macro avg       0.51      0.51      0.44      1753\n",
      "weighted avg       0.55      0.44      0.43      1753\n",
      "\n",
      "Precision: 0.3632781717888101\n",
      "Accuracy: 0.44381061038220193\n",
      "AUC: 0.5027133757961784\n"
     ]
    }
   ],
   "source": [
    "params_LGB= {'learning_rate': [0.001, 0.01, 0.1, 1.0],\n",
    "             'num_leaves': [31, 127],\n",
    "             'reg_alpha': [0.1, 0.5],\n",
    "             'min_data_in_leaf': [30, 50, 100, 300, 400]}\n",
    "\n",
    "gs_lgm= GridSearchCV(estimator= lgm, param_grid= params_LGB, cv=5, scoring='precision', n_jobs=-1, verbose=2)\n",
    "gs_lgm.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "tuned_lgm= gs_lgm.best_estimator_\n",
    "y_pred_tuned_lgm= tuned_lgm.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_lgm= tuned_lgm.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_lgm, labels= tuned_lgm.classes_)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_tuned_lgm, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_lgm, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_lgm))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_lgm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdbeff2",
   "metadata": {},
   "source": [
    "--- Tuned LGBM 1 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d02b27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6400 candidates, totalling 32000 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Number of positive: 2511, number of negative: 2511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1171\n",
      "[LightGBM] [Info] Number of data points in the train set: 5022, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[[292 833]\n",
      " [140 488]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.26      0.38      1125\n",
      "           1       0.37      0.78      0.50       628\n",
      "\n",
      "    accuracy                           0.44      1753\n",
      "   macro avg       0.52      0.52      0.44      1753\n",
      "weighted avg       0.57      0.44      0.42      1753\n",
      "\n",
      "Precision: 0.36941710825132473\n",
      "Accuracy: 0.44495151169423847\n",
      "AUC: 0.5131012031139419\n"
     ]
    }
   ],
   "source": [
    "params_LGB= {\n",
    "    'learning_rate': np.logspace(-3, 0, 10),\n",
    "    'num_leaves': [20, 31, 50, 70, 100],\n",
    "    'reg_alpha': [0.01, 0.1, 0.5, 1.0],\n",
    "    'min_data_in_leaf': [20, 50, 100, 200],\n",
    "    'max_depth': [-1, 10, 20, 30],\n",
    "    'boosting_type': ['gbdt', 'dart']\n",
    "}\n",
    "\n",
    "gs_lgm= GridSearchCV(estimator= lgm, param_grid= params_LGB, cv= 5, scoring= 'precision', n_jobs= -1, verbose= 2)\n",
    "gs_lgm.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "\n",
    "tuned_lgm1= gs_lgm.best_estimator_\n",
    "y_pred_tuned_lgm1= tuned_lgm1.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_lgm1= tuned_lgm1.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_lgm1, labels= tuned_lgm1.classes_)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_tuned_lgm1, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_lgm1, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_lgm1))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_lgm1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd7b914",
   "metadata": {},
   "source": [
    "--- Tuned LGBM RandomizedSearchCV 2 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdb5c0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Info] Number of positive: 2511, number of negative: 2511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1171\n",
      "[LightGBM] [Info] Number of data points in the train set: 5022, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[[261 864]\n",
      " [121 507]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.23      0.35      1125\n",
      "           1       0.37      0.81      0.51       628\n",
      "\n",
      "    accuracy                           0.44      1753\n",
      "   macro avg       0.53      0.52      0.43      1753\n",
      "weighted avg       0.57      0.44      0.40      1753\n",
      "\n",
      "Precision: 0.36980306345733044\n",
      "Accuracy: 0.4381061038220194\n",
      "AUC: 0.5177070063694268\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "param_dist = {\n",
    "    'learning_rate': uniform(0.001, 0.1),\n",
    "    'num_leaves': randint(20, 100),\n",
    "    'reg_alpha': uniform(0.01, 1.0),\n",
    "    'min_data_in_leaf': randint(20, 200),\n",
    "    'max_depth': randint(5, 30),\n",
    "    'boosting_type': ['gbdt', 'dart']\n",
    "}\n",
    "\n",
    "rs_lgm= RandomizedSearchCV(estimator=lgm, param_distributions= param_dist, n_iter= 100, cv= 5, scoring= 'precision', random_state= 15, n_jobs= -1, verbose= 2)\n",
    "rs_lgm.fit(X_sm_tl_selected, y_sm_tl)\n",
    "\n",
    "\n",
    "tuned_lgm2= rs_lgm.best_estimator_\n",
    "y_pred_tuned_lgm2= tuned_lgm2.predict(X_sm_tl_test_selected)\n",
    "y_pred_prob_tuned_lgm2= tuned_lgm2.predict_proba(X_sm_tl_test_selected)[:,1]\n",
    "\n",
    "cm= confusion_matrix(y_test, y_pred_tuned_lgm2, labels= tuned_lgm2.classes_)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_tuned_lgm2, zero_division=0))\n",
    "print('Precision:', precision_score(y_test, y_pred_tuned_lgm2, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_tuned_lgm2))\n",
    "print('AUC:', roc_auc_score(y_test, y_pred_prob_tuned_lgm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0780f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b57855ee",
   "metadata": {},
   "source": [
    "--- Visualisation ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9984fadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Model  Precision Score\n",
      "2          Tuned Decision Tree Precision1:         0.371205\n",
      "3   Tuned Decision Tree - RS - Precision2:         0.371205\n",
      "4          Tuned Decision Tree Precision3:         0.371205\n",
      "16                  Tuned LGBM Precision2:         0.369803\n",
      "15                  Tuned LGBM Precision1:         0.369417\n",
      "9                           SVM Precision:         0.369231\n",
      "12            Tuned SVM - RS - Precision2:         0.366825\n",
      "1           Tuned Decision Tree Precision:         0.365678\n",
      "5                    GaussianNB Precision:         0.365635\n",
      "13                         LGBM Precision:         0.363436\n",
      "14                   Tuned LGBM Precision:         0.363278\n",
      "8      Tuned GaussianNB - RS - Precision2:         0.358925\n",
      "7             Tuned GaussianNB Precision1:         0.358650\n",
      "6              Tuned GaussianNB Precision:         0.358650\n",
      "10                    Tuned SVM Precision:         0.356140\n",
      "11                   Tuned SVM Precision1:         0.354571\n",
      "0                 Decision Tree Precision:         0.352227\n"
     ]
    }
   ],
   "source": [
    "precision_scores= {\n",
    "                    'Decision Tree Precision:': precision_score(y_test, y_pred_dt, zero_division= 0),\n",
    "                    'Tuned Decision Tree Precision:': precision_score(y_test, y_pred_tuned_dt, zero_division= 0),\n",
    "                    'Tuned Decision Tree Precision1:': precision_score(y_test, y_pred_tuned_dt1, zero_division= 0),\n",
    "                    'Tuned Decision Tree - RS - Precision2:': precision_score(y_test, y_pred_tuned_dt2, zero_division= 0),\n",
    "                    'Tuned Decision Tree Precision3:': precision_score(y_test, y_pred_tuned_dt3, zero_division= 0),\n",
    "                    'GaussianNB Precision:': precision_score(y_test, y_pred_nb, zero_division= 0),\n",
    "                    'Tuned GaussianNB Precision:': precision_score(y_test, y_pred_tuned_nb, zero_division= 0),\n",
    "                    'Tuned GaussianNB Precision1:': precision_score(y_test, y_pred_tuned_nb1, zero_division= 0),\n",
    "                    'Tuned GaussianNB - RS - Precision2:': precision_score(y_test, y_pred_tuned_nb2, zero_division= 0),\n",
    "                    'SVM Precision:': precision_score(y_test, y_pred_svc, zero_division= 0),\n",
    "                    'Tuned SVM Precision:': precision_score(y_test, y_pred_tuned_svc, zero_division= 0),\n",
    "                    'Tuned SVM Precision1:': precision_score(y_test, y_pred_tuned_svc1, zero_division= 0),\n",
    "                    'Tuned SVM - RS - Precision2:': precision_score(y_test, y_pred_tuned_svc2, zero_division= 0),\n",
    "                    'LGBM Precision:': precision_score(y_test, y_pred_lgm, zero_division= 0),\n",
    "                    'Tuned LGBM Precision:': precision_score(y_test, y_pred_tuned_lgm, zero_division= 0),\n",
    "                    'Tuned LGBM Precision1:': precision_score(y_test, y_pred_tuned_lgm1, zero_division= 0),\n",
    "                    'Tuned LGBM Precision2:': precision_score(y_test, y_pred_tuned_lgm2, zero_division= 0)\n",
    "                  }\n",
    "\n",
    "annova_precision= pd.DataFrame(list(precision_scores.items()), columns= ['Model', 'Precision Score'])\n",
    "annova_precision= annova_precision.sort_values(by= 'Precision Score', ascending=False)\n",
    "print(annova_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "209b0ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy Score\n",
      "9                           SVM Accuracy:        0.496292\n",
      "2          Tuned Decision Tree Accuracy1:        0.491728\n",
      "3   Tuned Decision Tree - RS - Accuracy2:        0.491728\n",
      "4          Tuned Decision Tree Accuracy3:        0.491728\n",
      "6              Tuned GaussianNB Accuracy:        0.488876\n",
      "7             Tuned GaussianNB Accuracy1:        0.488876\n",
      "12            Tuned SVM - RS - Accuracy2:        0.481460\n",
      "0                 Decision Tree Accuracy:        0.475185\n",
      "1           Tuned Decision Tree Accuracy:        0.471192\n",
      "11                   Tuned SVM Accuracy1:        0.462065\n",
      "10                    Tuned SVM Accuracy:        0.454649\n",
      "5                    GaussianNB Accuracy:        0.453508\n",
      "15                  Tuned LGBM Accuracy1:        0.444952\n",
      "14                   Tuned LGBM Accuracy:        0.443811\n",
      "16                  Tuned LGBM Accuracy2:        0.438106\n",
      "13                         LGBM Accuracy:        0.429549\n",
      "8      Tuned GaussianNB - RS - Accuracy2:        0.390188\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores= {\n",
    "                    'Decision Tree Accuracy:': accuracy_score(y_test, y_pred_dt),\n",
    "                    'Tuned Decision Tree Accuracy:': accuracy_score(y_test, y_pred_tuned_dt),\n",
    "                    'Tuned Decision Tree Accuracy1:': accuracy_score(y_test, y_pred_tuned_dt1),\n",
    "                    'Tuned Decision Tree - RS - Accuracy2:': accuracy_score(y_test, y_pred_tuned_dt2),\n",
    "                    'Tuned Decision Tree Accuracy3:': accuracy_score(y_test, y_pred_tuned_dt3),\n",
    "                    'GaussianNB Accuracy:': accuracy_score(y_test, y_pred_nb),\n",
    "                    'Tuned GaussianNB Accuracy:': accuracy_score(y_test, y_pred_tuned_nb),\n",
    "                    'Tuned GaussianNB Accuracy1:': accuracy_score(y_test, y_pred_tuned_nb1),\n",
    "                    'Tuned GaussianNB - RS - Accuracy2:': accuracy_score(y_test, y_pred_tuned_nb2),\n",
    "                    'SVM Accuracy:': accuracy_score(y_test, y_pred_svc),\n",
    "                    'Tuned SVM Accuracy:': accuracy_score(y_test, y_pred_tuned_svc),\n",
    "                    'Tuned SVM Accuracy1:': accuracy_score(y_test, y_pred_tuned_svc1),\n",
    "                    'Tuned SVM - RS - Accuracy2:': accuracy_score(y_test, y_pred_tuned_svc2),\n",
    "                    'LGBM Accuracy:': accuracy_score(y_test, y_pred_lgm),\n",
    "                    'Tuned LGBM Accuracy:': accuracy_score(y_test, y_pred_tuned_lgm),\n",
    "                    'Tuned LGBM Accuracy1:': accuracy_score(y_test, y_pred_tuned_lgm1),\n",
    "                    'Tuned LGBM Accuracy2:': accuracy_score(y_test, y_pred_tuned_lgm2)\n",
    "                  }\n",
    "\n",
    "annova_accuracy= pd.DataFrame(list(accuracy_scores.items()), columns= ['Model', 'Accuracy Score'])\n",
    "annova_accuracy= annova_accuracy.sort_values(by= 'Accuracy Score', ascending=False)\n",
    "print(annova_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7f99f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Model  AUC Score\n",
      "9                           SVM AUC:   0.520795\n",
      "16                  Tuned LGBM AUC2:   0.517707\n",
      "2          Tuned Decision Tree AUC1:   0.516418\n",
      "3   Tuned Decision Tree - RS - AUC2:   0.516418\n",
      "4          Tuned Decision Tree AUC3:   0.516418\n",
      "15                  Tuned LGBM AUC1:   0.513101\n",
      "1           Tuned Decision Tree AUC:   0.510919\n",
      "13                         LGBM AUC:   0.510502\n",
      "12            Tuned SVM - RS - AUC2:   0.510279\n",
      "5                    GaussianNB AUC:   0.503921\n",
      "8      Tuned GaussianNB - RS - AUC2:   0.503815\n",
      "14                   Tuned LGBM AUC:   0.502713\n",
      "11                   Tuned SVM AUC1:   0.500000\n",
      "10                    Tuned SVM AUC:   0.500000\n",
      "7             Tuned GaussianNB AUC1:   0.499131\n",
      "6              Tuned GaussianNB AUC:   0.499131\n",
      "0                 Decision Tree AUC:   0.492626\n"
     ]
    }
   ],
   "source": [
    "auc_scores= {\n",
    "                    'Decision Tree AUC:': roc_auc_score(y_test, y_pred_prob_dt),\n",
    "                    'Tuned Decision Tree AUC:': roc_auc_score(y_test, y_pred_prob_tuned_dt),\n",
    "                    'Tuned Decision Tree AUC1:': roc_auc_score(y_test, y_pred_prob_tuned_dt1),\n",
    "                    'Tuned Decision Tree - RS - AUC2:': roc_auc_score(y_test, y_pred_prob_tuned_dt2),\n",
    "                    'Tuned Decision Tree AUC3:': roc_auc_score(y_test, y_pred_prob_tuned_dt3),\n",
    "                    'GaussianNB AUC:': roc_auc_score(y_test, y_pred_prob_nb),\n",
    "                    'Tuned GaussianNB AUC:': roc_auc_score(y_test, y_pred_prob_tuned_nb),\n",
    "                    'Tuned GaussianNB AUC1:': roc_auc_score(y_test, y_pred_prob_tuned_nb1),\n",
    "                    'Tuned GaussianNB - RS - AUC2:': roc_auc_score(y_test, y_pred_prob_tuned_nb2),\n",
    "                    'SVM AUC:': roc_auc_score(y_test, y_pred_prob_svc),\n",
    "                    'Tuned SVM AUC:': roc_auc_score(y_test, y_pred_prob_tuned_svc),\n",
    "                    'Tuned SVM AUC1:': roc_auc_score(y_test, y_pred_prob_tuned_svc1),\n",
    "                    'Tuned SVM - RS - AUC2:': roc_auc_score(y_test, y_pred_prob_tuned_svc2),\n",
    "                    'LGBM AUC:': roc_auc_score(y_test, y_pred_prob_lgm),\n",
    "                    'Tuned LGBM AUC:': roc_auc_score(y_test, y_pred_prob_tuned_lgm),\n",
    "                    'Tuned LGBM AUC1:': roc_auc_score(y_test, y_pred_prob_tuned_lgm1),\n",
    "                    'Tuned LGBM AUC2:': roc_auc_score(y_test, y_pred_prob_tuned_lgm2)                    \n",
    "                  }\n",
    "\n",
    "annova_auc= pd.DataFrame(list(auc_scores.items()), columns= ['Model', 'AUC Score'])\n",
    "annova_auc= annova_auc.sort_values(by= 'AUC Score', ascending=False)\n",
    "print(annova_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2ac15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dee7d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d9919c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011f3570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
